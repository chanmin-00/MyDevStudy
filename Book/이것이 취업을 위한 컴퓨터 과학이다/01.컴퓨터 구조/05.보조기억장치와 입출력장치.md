보조기억장치는 **메모리의 휘발성을 보완**하는 동시에, 메모리보다 **더 큰 저장 공간**을 제공한다.

# RAID

### 보조기억장치의 종류

오늘날 대중적으로 활용되고 있는 보조기억장치는 크게 두 가지가 있다. 하나는 **하드 디스크 드라이브(HDD)** 이고, 또 하나는 **플래시 메모리 기반 저장장치**이다.

하드 디스크는 **자기적인 방식으로 데이터를 읽고 쓰는 보조기억장치**이다. 하드 디스크 안에는 **동그란 원판 모양의 플래터(Platter)** 가 있으며, 그 위에 있는 **뾰족한 리더기(Head)** 를 통해 플래터에 저장된 데이터에 접근할 수 있다.

<img width="285" height="202" alt="image" src="https://github.com/user-attachments/assets/31f6bd04-602e-48ce-a104-30118c691ffa" />

플래시 메모리(Flash Memory)는 **전기적인 방식으로 데이터를 읽고 쓰는 반도체 기반 저장장치**이다. 우리가 흔히 사용하는 **USB 메모리, SD카드, SSD** 등이 모두 플래시 메모리 기반 저장장치에 해당한다.

이 중 보조기억장치로 주로 사용되는 플래시 메모리는 **SSD(Solid State Drive)** 이다. 노트북이나 데스크탑을 열어보면 플래시 메모리를 직접 확인할 수 있다.

<img width="244" height="150" alt="image" src="https://github.com/user-attachments/assets/1ded1776-c9f9-4cd3-81f8-629d9ec80219" />

### 보조기억장치의 역할

보조기억장치의 본분은 크게 두 가지이다.

- **전원이 꺼져도 데이터를 안전하게 보관하는 것.**
- **CPU가 필요로 하는 정보를 빠른 성능으로 메모리에게 전달하는 것.**

즉, 보조기억장치에서 데이터를 **안전하고 빠르게 다루는 방법**이 중요하다. 이를 위해 활용할 수 있는 기술이 바로 **RAID** 이다.

### RAID

**RAID(Redundant Array of Independent Disks)**는 데이터의 안정성 혹은 성능을 확보하기 위해 **여러 개의 독립적인 보조기억장치를 하나의 보조기억장치처럼 사용하는 기술**이다. 하드 디스크나 SSD 모두 RAID로 구성할 수 있다.

<img width="340" height="152" alt="image" src="https://github.com/user-attachments/assets/f9c6cacb-859d-4678-bc5f-423be9be2985" />

RAID를 구성하는 방법에는 여러 가지가 있으며, 이를 RAID 레벨(RAID Level) 이라고 표현한다. 대표적으로 RAID 0, RAID 1, RAID 2, RAID 3, RAID 4, RAID 5, RAID 6 이 있으며, 이로부터 RAID 10, RAID 50 등이 파생된다.

### RAID0

**RAID 0**은 데이터를 여러 보조기억장치에 **단순하게 나누어 저장하는 구성 방식**이다. 데이터가 각각의 하드 디스크에 번갈아 가며 저장되며, 저장되는 데이터는 하드 디스크의 개수만큼 나뉘어 저장된다.

이렇게 **줄무늬처럼 분산되어 저장된 데이터**를 **스트라이프(Stripe)**라 하고, 이러한 동작 방식을 **스트라이핑(Striping)**이라고 한다.

<img width="507" height="242" alt="image" src="https://github.com/user-attachments/assets/81b0d0ac-1dbb-4bff-9d8c-b2c43feffc8c" />

RAID 0의 장점은 **빠른 입출력 속도**이다. 하나의 대용량 저장장치를 사용했다면 여러 번에 걸쳐 읽고 써야 했을 데이터를, RAID 0에서는 여러 디스크가 동시에 데이터를 읽고 쓸 수 있다.

예를 들어, A1, A2, A3, A4 데이터를 동시에 읽을 때 하드 디스크 1~4가 **병렬로 데이터를 읽고 쓰기 때문에** 하나의 디스크로 읽고 쓰는 것보다 훨씬 빠르다. 따라서 4TB짜리 저장장치 1개보다, 1TB 디스크 4개로 RAID 0을 구성했을 때 이론상 약 4배 빠른 속도를 얻을 수 있다.

그러나 RAID 0의 단점은 **데이터의 안전성이 보장되지 않는다는 점**이다.

예를 들어 위 그림에서 하드 디스크 1에 문제가 발생하면, 나머지 하드 디스크(2, 3, 4)에 저장된 데이터도 불완전한 상태가 되어 복구가 불가능하다.

즉, RAID 0은 속도는 빠르지만, 데이터의 안정성을 희생한 방식이다.

### RAID1

**RAID 1**은 데이터를 저장할 때 **완전한 복사본을 함께 만들어 저장하는 구성 방식**으로, 이 때문에 **미러링(Mirroring)** 이라고 부른다. 

이 방식은 데이터를 복제해 두기 때문에 **복구가 간단하고 안정성이 높다는 장점**이 있다. 예를 들어, 4개의 하드 디스크를 RAID 1으로 구성하면 그중 절반은 백업(복사본)을 저장하는 용도로 사용된다.

따라서 데이터를 쓸 때는 원본과 복사본 **두 곳에 동시에 기록**해야 하므로 RAID 0보다 **쓰기 속도가 느리다.** 또한 RAID 1은 **복사본을 저장하는 만큼 사용 가능한 용량이 줄어든다**는 단점이 있다.

즉, 4개의 디스크를 사용하더라도 실제 저장 가능한 용량은 절반인 **2개의 디스크 용량**에 해당한다.

<img width="447" height="238" alt="image" src="https://github.com/user-attachments/assets/99813eae-e73f-415d-bc5e-2b861df9a2d5" />

### RAID4

**RAID 4**는 **패리티(Parity) 정보를 저장하는 디스크를 별도로 두는 구성 방식**이다. 여기서 **패리티**란, 데이터의 **오류를 검출할 수 있는 정보**를 의미한다.

RAID 4는 오류 검출용 디스크를 따로 두기 때문에 RAID 1에 비해 적은 수의 하드 디스크로도 데이터를 안전하게 보관할 수 있다는 장점이 있다.

그러나 단점도 존재한다. 데이터를 새로 저장할 때마다 패리티 정보를 저장하는 디스크에도 동시에 데이터를 써야 하기 때문에, **패리티 디스크에 병목 현상**이 발생할 수 있다.

즉, 패리티 정보를 담당하는 디스크가 데이터 처리 속도를 저해하는 지점이 될 수 있다.

<img width="503" height="236" alt="image" src="https://github.com/user-attachments/assets/9ca21786-44d0-49b7-a28f-5db471a1e6e9" />

### RAID5

**RAID 5**는 **패리티 정보를 분산하여 저장하는 구성 방식**이다. 패리티를 분산 저장함으로써 **RAID 4의 단점인 병목 현상**을 보완할 수 있다.

<img width="553" height="311" alt="image" src="https://github.com/user-attachments/assets/56797c68-5d4c-40c2-bc49-e5491dcc8135" />

예를 들어, 데이터 D에 대한 패리티 정보는 하드 디스크 1에, 데이터 C에 대한 패리티 정보는 하드 디스크 2에 저장하는 식으로 패리티를 여러 디스크에 나누어 저장한다.

이렇게 함으로써 하나의 디스크에 부하가 집중되지 않고, 보다 균형 잡힌 입출력 성능을 얻을 수 있다.

### RAID6

**RAID 6**은 기본적으로 RAID 5와 같은 구조이지만, 서로 다른 2개의 패리티 정보를 두는 구성 방식이다. 즉, 오류를 검출하고 복구할 수 있는 **두 개의 수단을 동시에 보유**한 셈이다.

RAID 6은 RAID 4나 RAID 5보다 더 높은 안정성을 가진다. 그러나 데이터를 저장할 때마다 두 개의 패리티 정보를 함께 기록해야 하므로 **쓰기 속도는 상대적으로 느리다.**

예를 들어, 저장하려는 A 데이터는 하드 디스크 1, 2, 3에 저장하고, 그에 대한 패리티 비트는 하드 디스크 4와 5에 저장하는 방식으로 동작한다.

<img width="555" height="248" alt="image" src="https://github.com/user-attachments/assets/14dd5dda-6b65-47a3-924f-dee93b36022c" />

저장하려는 A의 데이터는 하드디스크는 1,2,3에 저장하고 패리티 비트는 하드 디스크 4, 하드디스크 5에 저장하는 방식으로 한다.

RAID 레벨마다 각각의 장단점이 존재하며, 어떤 RAID 구성을 선택하느냐는 안정성, 속도, 저장 효율성 중 무엇을 우선시할지에 따라 달라진다.

### cf) Nested RAID

**Nested RAID**는 **서로 다른 RAID 레벨을 혼합한 구성 방식**을 말한다. 즉, 두 가지 이상의 RAID 방식을 결합하여 각 RAID 레벨의 장점을 함께 활용하는 방식이다.

대표적인 예로는 **RAID 0과 RAID 1을 혼합한 RAID 10**, **RAID 0과 RAID 5를 혼합한 RAID 50** 이 있다.

이처럼 여러 RAID 레벨을 혼합하여 구성한 방식을 **Nested RAID(중첩 RAID)** 라고 한다.

<img width="358" height="206" alt="image" src="https://github.com/user-attachments/assets/1f88ba65-b51a-4ac5-ac78-6ae4b41ef478" />

# 입출력 기법

보조기억장치는 메모리를 보조하는 역할을 수행하는 특별한 입출력 장치로 볼 수 있다. 즉, 보조기억장치 역시 컴퓨터 내부와 정보를 주고받는 입출력 장치의 일종이다. 이 절에서는 다양한 입출력장치가 컴퓨터 내부와 데이터를 교환하는 방식,즉 입출력 기법에 대해 살펴본다.

## 장치 컨트롤러와 장치 드라이버

컴퓨터 외부에는 다양한 입출력장치가 존재한다. 그런데 같은 종류의 장치라 하더라도 **제조사마다 규격과 작동 방식이 다르기 때문에**, CPU 입장에서 **모든 입출력장치의 동작 방식을 직접 이해하고 제어하기란 어렵다.**

이 문제를 해결하기 위해 입출력장치는 CPU와 직접 연결되지 않고, **장치 컨트롤러(Device Controller)** 라는 하드웨어를 통해 연결된다. 즉, **CPU ↔ 장치 컨트롤러 ↔ 입출력장치** 의 구조로 동작한다.

모든 입출력장치는 **자신만의 장치 컨트롤러를 통해 컴퓨터 내부와 연결되어 정보를 주고받는다.** 따라서 장치 컨트롤러는 **CPU와 입출력장치 사이에서 통신을 중개하는 하드웨어**, 즉 **중개자 역할을 하는 하드웨어 장치**라고 할 수 있다.

### **CPU와 장치 컨트롤러의 관계**

CPU가 장치를 제어하는 과정도 결국 프로그램 실행의 일부분이다. CPU는 명령어를 실행하는 과정에서 장치 컨트롤러와 상호작용하며 입출력장치를 작동시킨다.

이때, CPU가 장치 컨트롤러와 상호작용하는 방법을 정의한 프로그램이 바로 장치 드라이버(Device Driver) 이다.

### 장치 드라이버

장치 드라이버는 **특정 장치 컨트롤러의 동작 방식을 이해하고**, 그 컨트롤러가 컴퓨터 내부와 정보를 주고받을 수 있도록 도와주는 프로그램이다.

즉, 장치 드라이버가 없다면 CPU는 장치 컨트롤러의 작동 방식을 알 수 없으므로 **해당 입출력장치를 사용할 수 없다.** 대부분의 장치 드라이버는 운영체제(OS)에 기본 포함되어 있어, 별도의 설치 없이도 키보드, 마우스, 모니터 등의 장치를 바로 사용할 수 있다. 하지만 대형 프린터나 특수 장비처럼 일반적이지 않은 입출력장치는 별도의 장치 드라이버를 설치해야만 작동한다.

### **입출력 수행 방식**

**CPU와 장치 컨트롤러가 데이터를 주고받는 방식, 즉 입출력 작업을 수행하는 방법에는 세 가지가 있다.**

1. **프로그램 입출력**
2. **인터럽트 기반 입출력**
3. **DMA 입출력**

## 프로그램 입출력

**프로그램 입출력**은 이름 그대로, **프로그램 속 명령어로 입출력 작업을 수행하는 방식**이다. 즉, CPU가 직접 입출력 명령어를 실행하여 장치 컨트롤러와 상호작용하고, 이를 통해 입출력장치를 제어한다.

예를 들어, “프린터 컨트롤러의 상태를 확인하라” “하드 디스크 컨트롤러에 10을 써라” 와 같은 명령어를 CPU가 실행함으로써 **장치 컨트롤러와 데이터를 주고받고**, 그 결과로 입출력 작업이 수행된다.

### 프로그램 입출력의 두 종류

프로그램 입출력은 **입출력장치의 주소를 식별하는 방식**에 따라 다음 두 가지로 나뉜다.

1. **고립형 입출력 (Isolated I/O)**
    
    고립형 입출력은 입출력장치에 접근하는 주소 공간과 메모리에 접근하는 주소 공간을 완전히 분리하여 관리하는 방식이다.
    
    즉, 입출력장치 전용 주소 공간이 따로 존재하며, 이 공간에 접근하기 위해서는 입출력 전용 명령어가 필요하다. CPU는 메모리에 접근할 때 사용하는 명령어와는 별도로, 입출력장치 접근을 위한 전용 명령어를 사용해야 한다.
    

1. **메모리 맵 입출력 (Memory-Mapped I/O)**
    
    메모리 맵 입출력은 입출력장치와 메모리를 하나의 동일한 주소 공간으로 간주하는 방식이다. 즉, 메모리의 주소 공간 일부를 입출력장치 식별용으로 할당하여, 메모리에 접근하듯이 입출력장치에 접근할 수 있다.
    
    이 방식에서는 입출력 전용 명령어가 필요하지 않다. CPU는 일반적인 메모리 접근 명령어만으로 입출력장치에 데이터를 읽거나 쓸 수 있다.
    

<img width="474" height="196" alt="image" src="https://github.com/user-attachments/assets/34674f4c-cd5a-4d73-9e83-e6cce1a0f72a" />

## 인터럽트 기반 입출력: 다중 인터럽트

다중 인터럽트란, 여러 입출력장치로부터 동시에 인터럽트가 발생하는 상황을 말한다. 즉, CPU가 한 인터럽트를 처리하는 도중에 또 다른 인터럽트 요청이 발생하는 경우이다.

### 다중 인터럽트 기본 처리 방식

CPU가 인터럽트를 처리할 때, 플래그 레지스터 속 인터럽트 비트가 비활성화되어 있으면 CPU는 다른 하드웨어 인터럽트를 받아들이지 않는다.

따라서 CPU는 기본적으로 하나의 인터럽트를 처리한 뒤 다음 인터럽트를 순차적으로 처리한다.  하지만 실제 시스템에서는 인터럽트마다 우선순위가 존재한다. 즉, 더 중요한 인터럽트가 먼저 처리되도록 설계되어 있다

<img width="254" height="256" alt="image" src="https://github.com/user-attachments/assets/a5bab34b-54d7-44a3-abcb-705cfbc59b57" />

### 우선순위 처리

만약 CPU가 인터럽트 A를 처리하는 도중, 인터럽트 B가 새로 발생했는데 B의 우선순위가 더 높다면, CPU는 다음과 같이 동작한다.

1. 현재 실행 중인 인터럽트 A의 처리를 일시 중단한다.
2. 우선순위가 높은 인터럽트 B를 먼저 처리한다.
3. B 처리가 완료된 후, 다시 A의 처리를 이어간다.

즉, CPU는 플래그 레지스터의 인터럽트 비트가 활성화되어 있는 경우 혹은 비트 설정과 관계없이 무시할 수 없는 NMI(Non-Maskable Interrupt) 가 발생한 경우, 우선순위가 높은 인터럽트를 먼저 처리한다.

<img width="242" height="267" alt="image" src="https://github.com/user-attachments/assets/ed1b7885-508f-4011-8f21-5ad7d4a714d3" />

### **프로그래머블 인터럽트 컨트롤러 (PIC)**

다중 인터럽트를 효율적으로 처리하기 위해 하드웨어적으로 프로그래머블 인터럽트 컨트롤러(PIC)가 사용된다.

PIC는 여러 장치 컨트롤러와 연결되어 있으며, 이들로부터 전달된 하드웨어 인터럽트 요청의 우선순위를 판단한다. 그리고 CPU에게 **현재 어떤 인터럽트를 먼저 처리해야 하는지** 알려준다.

<img width="283" height="157" alt="image" src="https://github.com/user-attachments/assets/4fbd6fd5-1a7f-4738-a526-1a9b540b64e8" />

PIC에는 여러 개의 핀(Pin) 이 존재하며, 각 핀에는 특정 하드웨어 장치가 연결되어 있어 그 장치가 CPU에 인터럽트 요청을 보낼 수 있도록 설계되어 있다.

예를 들어, 첫 번째 핀은 타이머 인터럽트, 두 번째 핀은 키보드 인터럽트를 담당하도록 설정할 수 있다. 단, PIC는 무시할 수 없는 인터럽트(NMI) 의 우선순위를 판별하지 않는다. NMI는 CPU가 반드시 처리해야 하는 최우선 인터럽트이기 때문이다.

<img width="504" height="298" alt="image" src="https://github.com/user-attachments/assets/bd03ac02-6b7d-414f-8237-afd4ba098010" />

일반적으로 하나의 PIC만으로는 모든 하드웨어 인터럽트를 관리하기 어려우므로, 2개 이상의 계층적 구조로 구성된다.

## DMA 입출력

프로그램 입출력과 인터럽트 기반 입출력의 공통점은, **CPU가 입출력장치와 메모리 간 데이터 이동을 직접 주도한다는 점**이다. 즉, 데이터가 **반드시 CPU를 거쳐야만 이동**할 수 있다.

예를 들어, 입출력장치의 데이터를 메모리에 저장해야 하는 경우 CPU는 다음과 같은 과정을 거친다.

1. 장치 컨트롤러로부터 데이터를 하나씩 읽어 레지스터에 적재한다.
2. 레지스터에 적재한 데이터를 하나씩 메모리에 저장한다.

반대로, 메모리의 데이터를 입출력장치로 내보낼 때도 CPU는 메모리에서 데이터를 하나씩 읽어 레지스터에 적재한 뒤, 적재된 데이터를 하나씩 입출력장치에 전송해야 한다.

<img width="646" height="275" alt="image" src="https://github.com/user-attachments/assets/a14229b3-5911-4158-a845-dbed2dd7cb92" />

이처럼 **모든 데이터 이동이 CPU를 거쳐야 한다면**, CPU의 연산 부담이 커지고 효율이 떨어진다. 이를 해결하기 위해 등장한 것이 바로 **DMA(Direct Memory Access)**, 즉 **직접 메모리 접근 입출력 방식**이다

### DMA의 개념

DMA 입출력은 이름 그대로, 입출력장치가 CPU를 거치지 않고 메모리에 직접 접근할 수 있는 방식이다.

이를 위해 시스템에는 **DMA 컨트롤러**라는 하드웨어가 존재한다. DMA 컨트롤러는 **시스템 버스**에 연결되어 있으며, 입출력장치들의 **장치 컨트롤러**는 입출력장치 전용 버스인 **입출력 버스(I/O Bus)** 를 통해 DMA 컨트롤러에 연결된다.

<img width="497" height="234" alt="image" src="https://github.com/user-attachments/assets/432c051c-098f-465e-945f-e32773e6c9ba" />

1. CPU가 DMA 컨트롤러에게 명령을 전달한다. 이때 CPU는 수행할 입출력장치의 주소, 수행할 연산 종류, 연산 대상이 되는 메모리 주소 등의 정보를 DMA 컨트롤러에 전달한다.
2. DMA 컨트롤러가 CPU 대신 입출력 작업을 수행한다. DMA 컨트롤러는 CPU의 개입 없이 장치 컨트롤러와 상호작용하며, 입출력장치에서 데이터를 읽어 메모리에 직접 저장하거나, 반대로 메모리 데이터를 입출력장치로 전송한다.
3. 작업 완료 후 CPU에 알림(인터럽트)

즉, CPU는 입출력 과정 전체를 직접 수행하지 않고, 명령을 내리고 완료 신호만 받으면 되므로 부담이 크게 줄어든다.

### PCIe 버스

대표적인 입출력 버스로는 **PCIe (Peripheral Component Interconnect Express)** 가 있다. 이는 기존 PCI 버스의 발전된 형태로, 현재 메인보드에서 가장 널리 사용되는 입출력 버스 중 하나이다.

PCIe 버스는 SSD, GPU, 네트워크 인터페이스 카드(NIC) 등 다양한 입출력장치를 연결할 수 있으며, 버전과 레인(Lane) 의 수에 따라 속도가 달라진다.

- **버전:** PCIe 3.0, 4.0, 5.0처럼 숫자가 높을수록 더 빠른 데이터 전송 속도를 지원한다.
- **레인(Lane):** 버스를 통해 데이터를 송수신하는 물리적 통로의 개수를 의미한다. 쉽게 말해 데이터가 오가는 선로의 수이다.
    
    예를 들어,
    
    - 레인 2개 → 2배 속도
    - 레인 4개 → 4배 속도
    - 레인 8개 → 8배 속도
    
    따라서 PCIe 4.0 x4는 PCIe 4.0 버전의 4개 레인을 사용하는 구성을 의미한다.
    

PCIe 버스는 지속적으로 발전하고 있으며, 버전이 올라갈수록 더 많은 대역폭과 빠른 전송 속도를 제공한다.

# GPU의 용도와 처리 방식

원래 GPU는 Graphic Processing Unit이라는 이름 그대로, 화면에 그림을 그리기 위한 그래픽 처리 장치였다. 주로 3D 그래픽을 렌더링하거나 게임의 그래픽을 실시간으로 처리하는 데 사용되며, 데스크탑, 노트북, 심지어 스마트폰에도 필수 부품으로 자리 잡았다.

그러나 오늘날의 GPU는 더 이상 단순한 그래픽 전용 장치가 아니다. GPU의 연산 능력에 주목한 연구자들과 개발자들이 이를 **범용 연산(GPGPU: General-Purpose computing on GPUs)**에 활용하기 시작하면서, 인공지능 딥러닝, 암호화폐 채굴, 물리 시뮬레이션 등 다양한 분야에서 고속 연산 장치로 폭넓게 사용되고 있다.

### **병렬 처리 능력**

GPU가 범용 연산에 적합한 가장 큰 이유는 **병렬 처리**에 최적화된 구조 덕분이다. CPU가 일반적으로 수 개에서 수십 개의 코어를 가지는 데 비해, GPU는 수백에서 수천 개의 코어를 집적하고 있다. 이는 **하나의 복잡한 문제를 여러 개의 단순한 하위 문제로 나눈 뒤, 각 문제를 동시에 병렬로 처리하는 데 매우 유리**하다.

<img width="526" height="284" alt="image" src="https://github.com/user-attachments/assets/6b0b116f-d103-470b-9e9a-0e4e4f643d6c" />

예를 들어, 큰 계산 문제를 쪼갠 뒤 GPU의 각 코어에 나누어 처리시키면, 전체 연산 속도와 효율성을 크게 끌어올릴 수 있다. 이러한 방식은 **단순하고 반복적인 계산을 빠르게 해결해야 하는 분야에서 특히 효과적**이다.

### CPU vs GPU

비록 GPU가 특정 연산에서 CPU보다 훨씬 빠른 성능을 발휘할 수 있지만, **CPU를 완전히 대체할 수는 없다**. GPU의 개별 코어는 단순한 계산에는 빠르지만, 복잡한 분기나 조건 처리에는 효율이 떨어진다. 운영체제 제어나 다양한 소프트웨어 실행, 복잡한 명령어 수행 등은 여전히 CPU의 몫이며, GPU는 이와 같은 작업에 적합하지 않다.

결국 GPU는 독립적으로 전체 시스템을 운용할 수 없으며, **일반적으로는 CPU와 협력하는 보조 프로세서(coprocessor)**로 작동한다. 즉, GPU는 특정 연산을 빠르게 처리하는 데 특화된 장치이지, 범용 제어를 담당하는 중심 장치는 아니다.

이러한 CPU와 GPU의 역할 차이는 **메모리 접근 방식**에서도 뚜렷하게 드러난다. CPU는 지연을 줄이기 위해 정교한 캐시 시스템을 갖추고 있으며, 다양한 상황에 유연하게 대응하도록 설계되어 있다. 반면 GPU는 많은 양의 데이터를 빠르게 처리하는 데 집중되어 있어, 다수의 코어가 넓게 배치되고, 병렬 처리 효율을 높이는 방식으로 구성되어 있다.

GPU 내부에도 L1/L2 캐시가 존재하지만, 그 구조는 CPU처럼 복잡하기보다는 대량의 데이터를 빠르게 수용하고 처리하는 데에 초점을 맞추고 있다.
