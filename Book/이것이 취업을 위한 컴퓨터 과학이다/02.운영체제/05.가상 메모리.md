# 가상 메모리

- CPU는 메모리 내의 모든 번지에 어떤 값이 저장되어 있는지를 일일이 알고 있지 못합니다.
이는 CPU 내부의 저장공간인 레지스터가 메모리 크기만큼 충분하지 않기 때문입니다.
- 새로운 프로세스는 메모리에 새롭게 적재되며, 사용되지 않는 프로세스는 메모리에서 삭제됩니다.
- 즉, 메모리의 상태는 시시각각 변하고 있으며, CPU가 메모리에 존재하는 모든 프로세스의 주소를 실시간으로 기억하고 관리하는 것은 불가능합니다.

![image](https://github.com/user-attachments/assets/d52465f6-13da-4cd7-9bb4-f0c8788858d4)

# 물리 주소와 논리 주소

- CPU와 프로세스는 실제 하드웨어 주소인 물리 주소를 사용하는 것이 아니라, 각 프로세스에게 0번지부터 시작하는 논리 주소(Logical Address)를 사용합니다.
- 따라서 여러 프로세스가 동시에 실행 중이라면 각각은 동일하게 0번지부터 시작하는 논리 주소를 갖고 있습니다.
- 논리 주소와 물리 주소 간의 변환이 필요하며, 이를 위해 `MMU(Memory Management Unit)`라는 하드웨어가 존재합니다.
- MMU는 CPU와 메모리 사이에 위치하여, CPU가 이해하는 논리 주소를 메모리가 이해하는 물리 주소로 변환하는 역할을 수행합니다.

![image](https://github.com/user-attachments/assets/4ec3cea9-df7b-4db6-9a4a-6de41b1c316e)


# 스와핑과 연속 메모리 할당

## 스와핑(Swapping)

- 메모리에 적재된 프로세스 중 현재 실행되지 않는 프로세스들은 보조기억장치의 일부인 `스왑 영역`으로 이동됩니다.
- 이로써 확보된 메모리 공간에 다른 프로세스를 적재할 수 있게 되며, 이러한 과정을 `스와핑`이라고 합니다.
    - `스왑 아웃(Swap-Out)`: 메모리에서 스왑 영역으로 이동
    - `스왑 인(Swap-In)`: 스왑 영역에서 메모리로 복귀
- 스왑 인되는 프로세스는 반드시 이전에 있던 주소로 돌아오는 것이 아니라, 다른 물리 주소에 배치될 수도 있습니다.

![image](https://github.com/user-attachments/assets/5d8efaef-1294-4108-90d4-c6b8eaa5cda2)


## 연속 메모리 할당과 외부 단편화

- 프로세스를 메모리에 연속적으로 배치하는 방식을 `연속 메모리 할당`이라고 합니다.
- 하지만 이 방식은 시간이 지남에 따라 메모리 사이사이에 빈 공간이 생기는 `외부 단편화 문제`가 발생합니다.
- 예를 들어 총 50MB의 빈 공간이 있어도, 그 공간이 30MB와 20MB로 나뉘어 있다면 50MB 크기의 프로세스를 적재할 수 없습니다.
    
    
    ![image](https://github.com/user-attachments/assets/e14e4c56-69e0-4ecc-93c7-8acde5de2cbd)

    
- 이처럼 연속적인 메모리 공간이 없을 경우 발생하는 낭비를 `외부 단편화` 라고 합니다.

# 페이징을 통한 가상 메모리 관리

- 연속 메모리 할당은 다음과 같은 문제를 가집니다:
    1. `외부 단편화` : 빈 공간이 흩어져 있어 큰 프로세스를 적재하지 못함
    2. `물리 메모리 한계` : 메모리보다 큰 프로그램은 실행할 수 없음. 4GB 메모리로는 4GB 이상 프로그램을 실행할 수 없습니다.

![image](https://github.com/user-attachments/assets/dc456b93-064e-4d65-8233-afe77b78236c)

- 이 문제를 해결하기 위해 `가상 메모리`가 도입됩니다.
    - 프로그램의 일부만 메모리에 적재하고, 나머지는 디스크에 보관. 이를 통해 메모리를 실제 크기보다 더 크게 보이게 할 수 있습니다.
    - 실제 메모리보다 큰 프로그램도 실행 가능
- 이때 만들어지는 논리 주소 공간을 `가상 주소 공간`이라고 합니다
- 대표적인 가상 메모리 관리 기법에는 페이징과 세그멘테이션이 존재합니다.
    - `페이징`: 고정 크기 단위로 나누어 관리 (가장 널리 사용)
    - `세그멘테이션`: 가변 크기 단위로 나누어 관리

## 페이징

- 페이징은 프로세스의 논리 주소 공간을 일정한 크기의 페이지(Page)로 나누고, 물리 주소 공간도 동일한 크기의 프레임(Frame)으로 나눈 뒤, 각 페이지를 프레임에 할당하는 방식입니다.
    
    ![image](https://github.com/user-attachments/assets/71011e26-6308-4c84-818c-84d8cec45b81)

    
- 이 방식은 프로세스를 메모리 내에 불연속적으로 배치할 수 있게 하여 외부 단편화 문제를 해결합니다.
    - 하지만 모든 프로세스가 페이지 단위로 정확히 나뉘지는 않기 때문에 내부 단편화가 발생할 수 있습니다.
    - 예를 들어 페이지 크기가 10KB이고 프로세스 크기가 107KB이면, 마지막 1페이지의 3KB는 낭비됩니다.
    
    ![image](https://github.com/user-attachments/assets/639374cf-5c06-415e-b638-9240df962087)

    

### 세그멘테이션

- 세그멘테이션은 프로세스를 일정한 페이지 크기가 아닌 가변적인 크기의 세그먼트 단위로 나누는 방식입니다.
- 세그먼트는 코드, 데이터, 스택 등의 의미 있는 단위일 수 있습니다.
- 세그멘트는 크기가 일정하지 않기 때문에 외부 단편화가 발생할 수 있습니다.
    
    ![image](https://github.com/user-attachments/assets/aa9c1daf-84f6-444e-920b-778e0c324634)

    
- 페이징 기법에서도 스와핑은 사용 가능합니다. 다만 프로세스 전체가 아닌, 페이지 단위로 스왑이 이루어집니다.
    - `페이지 아웃`: 사용하지 않는 페이지를 디스크로 이동
    - `페이지 인`: 필요한 페이지를 다시 메모리로 불러옴
- 이러한 구조 덕분에:
    - 프로세스 전체를 메모리에 올릴 필요가 없으며, 일부만 메모리에 있어도 실행 가능합니다.
    - 따라서 논리 메모리 크기가 물리 메모리보다 클 수 있습니다.
    - 이는 페이징 기법이 실제보다 큰 프로그램 실행을 가능하게 하는 이유입니다.
        
        ![image](https://github.com/user-attachments/assets/d3848184-9501-419e-9167-7092b8b9478e)

        
- 하지만 페이지들이 메모리에 불연속적으로 배치되기 때문에, CPU는 어떤 페이지가 어떤 프레임에 있는지를 스스로 알 수 없습니다.
    - 이를 해결하기 위해 페이지 테이블이 필요합니다.

## 페이지 테이블

- CPU는 각 프로세스가 어떤 페이지를 어떤 프레임에 가지고 있는지 모릅니다.
- 따라서 페이지 테이블(Page Table)을 사용하여 페이지 번호와 프레임 번호를 매핑합니다.
- 각 프로세스는 자신의 페이지 테이블을 가지고 있으며, CPU는 이를 참조하여 메모리 접근을 수행합니다.

![image](https://github.com/user-attachments/assets/3d05866f-0155-4c3e-a038-268070e43ee4)


### 페이지 테이블 엔트리(PTE)

- 페이지 테이블(Page Table)은 프로세스의 각 페이지가 물리 메모리의 어떤 프레임에 있는지를 기록한 표입니다.
- 각 행은 PTE(Page Table Entry)라고 부르며, 다음과 같은 정보를 포함합니다:
    - `유효 비트(valid bit)`: 메모리에 존재하면 1, 보조기억장치에 있으면 0
    - `보호 비트(protection bit)`: r(읽기), w(쓰기), x(실행) 권한 정보
    - `참조 비트(reference bit)`: 접근된 적이 있는지
    - `수정 비트(modified/dirty bit)`: 쓰기 작업이 있었는지 여부
        - 수정 비트 = 1 (쓰기 작업 존재) 인 경우에는 페이지를 메모리에서 제거할 때, 보조기억장치에 변경 내용을 반영해야 합니다.
        - 수정 비트 = 0 (읽기만 하거나 접근 없음) 인 경우에는 변경된 내용이 없기 때문에 추가 작업 없이 바로 제거 가능합니다.

![image](https://github.com/user-attachments/assets/d8f5893d-204b-4659-9ab4-6da1774a084e)


- CPU가 유효 비트가 0인 페이지에 접근하면 페이지 폴트(Page Fault)가 발생합니다. 이 경우 운영체제는 보조기억장치에서 해당 페이지를 메모리로 가져온 뒤 작업을 재개합니다.
    1. 현재 작업 상태 백업
    2. 페이지 폴트 처리 루틴 실행 (디스크에서 해당 페이지 로드)
    3. 유효 비트 1로 설정
    4. 다시 원래 작업을 재개

## 페이지 테이블 관리 기법

- 각 프로세스는 자신의 페이지 테이블을 메모리에 가지고 있으며, 해당 테이블이 위치한 주소는 PTBR(Page Table Base Register)를 통해 참조됩니다.
    - `PTBR`은 현재 실행 중인 프로세스의 페이지 테이블 시작 주소를 저장합니다.
    - 프로세스마다 고유하게 존재하며, 문맥 교환 시 PTBR도 함께 변경됩니다.

![image](https://github.com/user-attachments/assets/43bb13c9-c080-4617-a330-5c73d2358883)


- 운영체제가 모든 페이지 테이블을 메모리에 유지하면 다음과 같은 문제가 발생합니다

### 메모리 접근 횟수 증가

1. CPU는 주소 변환 시 페이지 테이블에 접근해 프레임 번호 확인
2. 프레임 주소로 실제 데이터 접근

- 결과적으로 2번의 메모리 접근이 필요합니다.
- 이를 보완하기 위해 `TLB(Translation Lookaside Buffer)`를 사용합니다. TLB는 페이지 테이블 일부를 캐시 형태로 저장하는 고속 메모리입니다.
    - CPU가 접근하려는 페이지 번호가 TLB에 있다면
        - `TLB 히트` : 빠르게 프레임 번호 확인 가능 (1회 접근)
    - TLB에 없다면
        - `TLB 미스`: 페이지 테이블로 접근하여 추가 조회 필요
- 성능을 위해 TLB 히트율을 높이는 것이 중요합니다.

![image](https://github.com/user-attachments/assets/52e14cdc-0fe4-4bfe-b0e5-f4901930c837)


### 메모리 낭비

- 프로세스가 커질수록 페이지 수가 많아지고, 이에 따라 페이지 테이블도 커지게 됩니다.
- 여러 프로세스의 페이지 테이블을 한꺼번에 메모리에 두면 메모리 용량을 과도하게 사용하게 됩니다.

### 계층적 페이징 (다단계 페이지 테이블)

- 이러한 비효율성을 해결하기 위해 운영체제는 계층적 페이징(Multi-Level Paging)을 사용합니다.
- 페이지 테이블을 여러 페이지로 나누고, 이들을 가리키는 상위 페이지 테이블(Outer Page Table)을 추가합니다.
- 실제 메모리에는 Outer Table만 항상 적재해두고, 필요한 하위 테이블은 보조기억장치에서 필요 시 접근합니다.
- 모든 페이지 테이블을 메모리에 올리지 않아도 되고, 메모리 절약 + 주소 변환 기능 유지가 가능해집니다.

![image](https://github.com/user-attachments/assets/935fb137-ee26-4d41-a6ff-2bc34bb4da93)


## 페이징 주소 체계

- 페이징 시스템의 논리 주소는 `<페이지 번호, 변위(offset)>` 형식입니다.
- MMU는 페이지 번호를 통해 프레임 번호를 찾고, 변위를 그대로 사용하여 물리 주소 `<프레임 번호, 변위>` 로 변환합니다.
    
    ![image](https://github.com/user-attachments/assets/4e435394-739a-4cc0-957f-76b2413f6705)

    
- 예를 들어 5번 페이지의 변위 2는 1번 프레임에 할당되었다면, 해당 주소는 실제 메모리의 10번지가 됩니다.
    
    ![image](https://github.com/user-attachments/assets/56c67511-0568-4888-b487-02afafb8390b)

    

# 페이지 교체 알고리즘

- `요구 페이징`은 프로세스 실행 시 필요한 일부 페이지만 메모리에 적재하는 방식입니다.
- 처음부터 모든 페이지를 올리지 않고, 접근 시점에 적재합니다.
- 요구 페이징의 동작 과정은 다음과 같습니다
    1. CPU가 페이지에 접근
    2. 유효 비트가 1 → 메모리에 존재 → 바로 접근
    3. 유효 비트가 0 → 페이지 폴트 발생
    4. 해당 페이지를 메모리로 불러오고 유효 비트를 1로 설정
    5. 명령 재실행
- 모든 페이지 없이도 실행 가능한 형태는 `순수 요구 페이징`이라고 하며, 초반엔 페이지 폴트가 많지만 필요한 페이지가 쌓이면 점차 줄어듭니다.

- 요구 페이징으로 점차 페이지를 메모리에 적재하다 보면 언젠가는 메모리가 가득 차게 됩니다. 이때 새 페이지를 넣기 위해 기존 페이지 중 일부를 보조기억장치로 내보내야 하며, 어떤 페이지를 내보낼지 결정하는 방식이 페이지 교체 알고리즘입니다.
    - 교체 알고리즘은 시스템 전체 성능에 직접적인 영향을 줍니다.
    - `좋은 알고리즘`: 사용되지 않을 페이지를 잘 골라 페이지 폴트를 줄임
    - `나쁜 알고리즘`: 곧 필요할 페이지를 내보내 폴트가 자주 발생
- 페이지 폴트는 디스크 접근을 동반하므로, 자주 발생하면 성능이 급격히 저하됩니다.

### 스래싱(Thrashing)

- 페이지 교체가 너무 자주 발생하면, CPU가 작업보다 페이징에 더 많은 시간을 소모하게 됩니다.
- 이러한 상태를 `스래싱(Thrashing)`이라고 하며, 시스템 성능 저하의 대표적인 원인 중 하나입니다.

### 대표적인 페이지 교체 알고리즘

1. `FIFO (First-In First-Out)`
    - 가장 먼저 들어온 페이지부터 제거
    - 초기에 적재되어 줄곧 참조되고 있는 페이지가 제거될 수 있음
2. `최적 페이지 교체 알고리즘`
    - 앞으로 가장 오랫동안 사용되지 않을 페이지 제거
    - 이론적으로 가장 효율적이나 실제 구현은 예측하기 어렵기 때문에 어렵
3. `LRU (Least Recently Used)`
    - 가장 오래 사용되지 않은 페이지 제거
    - 현실적으로 가장 널리 쓰임

### 페이지 폴트의 종류

- `메이저 폴트`: 디스크 접근이 필요한 경우 → 성능 저하 큼
- `마이너 폴트`: 메모리에 있으나 테이블에 반영되지 않은 경우이기 때문에 메이저 폴트에 비해 영향이 적음
- 성능 상의 악영향이 적은 페이지 폴트
