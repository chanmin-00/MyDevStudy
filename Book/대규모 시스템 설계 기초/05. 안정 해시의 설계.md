수평적 규모 확장성을 달성하기 위해서는 요청 또는 데이터를 서버에 균등하게 나누는 것이 중요하다. 안정 해시는 이를 달성하기 위해 보편적으로 사용하는 기술이다.

# 해시 키 재배치(rehash) 문제

N개의 캐시 서버가 있을 때, 각 서버들에 부하를 균등하게 나누기 위해서는 아래의 해시함수를 사용한다.

```
server Index = hash(key) % N
- N은 서버의 개수이다.
```

총 4대의 서버를 사용한다고 했을 때 각각의 키에 대해서 `해시 값`과 `서버 인덱스`를 계산하면 다음과 같이 나오게 된다.

<img width="261" height="225" alt="image" src="https://github.com/user-attachments/assets/96143ad2-8a3a-46ab-8db1-d32f4e5a5ec0" />

이와 같은 방법은 서버 풀(`server pool`)의 크기가 고정되어 있을 때, 데이터 분포가 균등할 때는 잘 동작하지만, **서버가 추가되거나 기존 서버가 삭제되면 문제가 생긴다.**

1번 서버가 장애를 일으켜 동작을 중단하면, 서버 풀의 크기는 3으로 변한다. 이 결과로 키에 대한 해시 값은 변하지 않지만 나머지 연산을 적용한 결과가 변경되어 서버 인덱스 값은 달라지게 된다.

- `해시 값 % 3` 의 연산이 적용된다.

<img width="251" height="215" alt="image" src="https://github.com/user-attachments/assets/366e83ae-cf11-4b32-bd56-1c5716c260ef" />

**새로운 나머지 연산이 적용됨으로써 장애가 발생한 1번 서버에 보관되어 있는 키 뿐만 아닌 대부분의 키가 재분배 된다**. 서버가 죽으면서 대부분 캐시 클라이언트가 데이터가 없는 엉뚱한 서버에 접속한다. 데이터가 없기 때문에 캐시 미스가 발생한다.

캐시 미스가 발생하는 문제를 안정 해시를 통해 해결할 수 있다.

# 안정 해시

> 해시 테이블 크기가 조정될 때 평균적으로 **오직 k/n 개의 키만 재배치 하는 기술**, 이에 반면 전통적 해시 테이블은 슬롯의 수가 바뀌면 거의 대부분 키를 재배치한다.
> 
- `k` : 키의 개수
- `n` :  슬롯(slot)의 개수

## 해시 공간과 해시 링

해시 함수로 f는 `SHA-1`을 사용한다고 하고, 이 함수의 출력 값의 범위는 x0, x1, …. xn과 같다고 가정한다. 

`SHA-1`의 해시 공간(`hash space`) 범위는 0부터 2$^{160}$-1까지라고 알려져 있다. 해시 공간을 그림으로 표현하면 다음과 같다.

<img width="240" height="250" alt="image" src="https://github.com/user-attachments/assets/a368facb-fdce-4bf3-95ed-24f8a3013e67" />


해시 공간의 양쪽을 구부려 접으면 해시 링(`hash ring`)이 만들어진다.

<img width="231" height="239" alt="image" src="https://github.com/user-attachments/assets/e2eb2fba-0393-41e5-8b2a-88dbb3592e76" />


## 해시 서버

해시 함수 f를 사용하면 서버 IP나 이름을 링위의 어떤 위치에 대응시킬 수 있다.

<img width="553" height="329" alt="image" src="https://github.com/user-attachments/assets/93e9c12f-a35b-437b-af7c-19264cd28932" />


- 4개의 서버를 이 해시 링 위에 배치한 결과다.

## 해시 키

해시 링을 위해 사용된 해시 함수는 해시 키 재배치 문제에 언급된 함수와는 다르며, 나머지 연산을 사용하지 않고 있다.

캐시할 키(key0, key1, key2, key3) 또한 해시 링 위의 어느 지점에 배치할 수 있다.

<img width="574" height="345" alt="image" src="https://github.com/user-attachments/assets/f47470a0-c2b6-4b9c-9523-e3dc9c64c14a" />


## 서버 조회

해시 링 기반에서 어떤 키가 저장되는 서버는, **키의 위치로부터 시계 방향으로 링을 탐색해 나가면서 만나는 첫 번째 서버**다.

<img width="580" height="375" alt="image" src="https://github.com/user-attachments/assets/b041e8ca-8a1e-448f-8fd9-233557b4889b" />


- key0은 서버 0, key1은 서버 1, key2는 서버 2 … 에 저장된다.

## 서버 추가

**위와 같은 키 배치 방법에서는 서버를 추가하더라도 키 가운데 일부만 재배치하면 된다.**

<img width="523" height="357" alt="image" src="https://github.com/user-attachments/assets/a47c6693-7b4c-428c-a5ce-b9d50785bb76" />


- 새로운 서버 4가 추가된 경우, key0만 재배치된다.
- key1, key2, key3은 같은 서버에 배치된다.
- 이렇게 되는 이유는 시계 방향으로 순회했을 때 처음으로 만나게 되는 서버가 서버4이기 때문이다.

## 서버 제거

**하나의 서버가 제거되면 키 가운데 일부만 재배치된다.**

<img width="574" height="397" alt="image" src="https://github.com/user-attachments/assets/0624e346-5596-4540-8908-d11fc7d1da79" />


- 서버1이 삭제되었을 때 key1만이 서버 2로 재배치된다.
- 나머지 키에는 영향이 없다.

# 안정 해시의 기본 구현법의 두 가지 문제

안정 해시 알고리즘의 기본 절차는 다음과 같다.

- 서버와 키를 균등 분포(`uniform distribution`) 해시 함수를 사용해 해시 링에 배치한다.
- **키의 위치에서 링을 시계 방향으로 탐색하다 만나는 최초의 서버가 키가 저장될 서버다.**

## 파티션의 균등 크기 유지

서버가 추가되거나 삭제되는 상황을 감안하면 파티션의 크기를 균등하게 유지하는 게 불가능하다.

- `파티션` : 인접한 서버 사이의 해시 공간

어떤 서버는 굉장히 작은 해시 공간을 할당 받고, 어떤 서버는 굉장히 큰 해시 공간을 할당 받는 상황이 가능하다는 것이다. 위의 서버 제거 상황에서 s2의 파티션이 다른 파티션 대비 거의 두 배로 커지는 상황이 발생했다.

## 키의 균등 분포

키의 균등 분포를 달성하기 어렵다.

<img width="473" height="285" alt="image" src="https://github.com/user-attachments/assets/86688ce7-562f-4153-9939-f02d7f8f615b" />


- 위와 같은 서버 배치 상황에서 서버1과 서버3은 아무 데이터도 갖지 않는 반면, 대부분의 키가 서버2에 보관될 것이다.

이 문제를 해결하기 위해 제안된 기법이 가상 노드(`Virtual node`) 또는 복제(`replica`)라 불리는 기법이 있다.

# 가상 노드

가상 노드는 실제 노드 또는 서버를 가리키는 노드로서, **하나의 서버는 링 위에 여러 개의 가상 노드를 가질 수 있다.**

<img width="501" height="363" alt="image" src="https://github.com/user-attachments/assets/8b26e9de-546b-46fd-afe9-e7188d9568f1" />


- 서버 0과 서버 1은 3개의 가상 노드를 갖는다. (숫자 3은 임의로 정한 것이며, 실제 시스템에서는 그보다 훨씬 큰 값이 사용된다.)
- 서버 0을 링에 배치하기 위해 s0 하나만 쓰는 대신, s0_0, s0_1, s0_2의 세 개 가상 노드를 사용한다.
- 여러 개의 가상 노드를 사용하기 때문에 각 서버는 하나가 아닌 여러 개의 파티션을 관리해야 한다.

키의 위치로부터 시계방향으로 링을 탐색하다 만나는 최초의 가상 노드가 해당 키가 저장될 서버가 된다. 

<img width="556" height="347" alt="image" src="https://github.com/user-attachments/assets/1eb7f3f9-1bdc-46bc-b999-870bc1c864b1" />


- k0의 위치로부터 링을 시계방향으로 탐색하다 만나는 최초의 가상 노드 s1_1가 나타내는 서버, 즉 서버 1이다.

가상 노드의 개수를 늘리면 키의 분포는 점점 더 균등해진다. 표준 편차가 작아져서 데이터가 고르게 분포되기 때문이다. 가상 노드의 개수를 더 늘리면 표준 편차의 값은 더 떨어진다.

- `표준 편차` : 데이터가 어떻게 펴져 나갔는지를 보이는 척도
- 100~200개의 가상 노드를 사용했을 경우 표준 편차 값은 평균의 5%~10%이다.

가상 노드의 개수를 더 늘리게 되면 데이터가 더욱 더 고르게 분포되게 되지만, 데이터를 저장할 공간은 더 많이 필요할 것이다. 특 트레이드 오프가 존재한다는 뜻이다. 시스템 요구사항에 맞도록 가상 노드 개수를 적절히 조정해야 할 것이다.

## 재배치할 키 결정

서버가 추가되거나 제거되면 데이터 일부는 재배치해야 한다.

<img width="512" height="360" alt="image" src="https://github.com/user-attachments/assets/0cec1773-9274-429d-b4e0-f520c684cb5d" />


- 서버 4가 추가 된 경우, 이에 영향을 받는 범위는 s4부터 그 반시계 방향에 있는 첫 번째 서버 s3까지이다.
- 즉 s3부터 s4 사이에 있는 키들을 s4로 재배치되어야 한다.

<img width="555" height="386" alt="image" src="https://github.com/user-attachments/assets/4f937336-b2cf-446a-bc6f-eaaf68be754a" />


- 서버 s1이 삭제되면 s1부터(삭제된 노드) 그 반시계 방향에 있는 최초 서버 s0 사이에 있는 키들이 s2로 재배치되어야 한다.

# 마치며

안정 해시의 이점은 다음과 같다.

- 서버가 추가되거나 삭제될 때 재배치되는 키의 수가 최소화된다.
- 데이터가 보다 균등하게 분포되므로 수평적 규모 확장성을 달성하기 쉽다.
- **핫스팟(hotspot)** 키 문제를 줄여준다. 특정한 샤드(`shard`)에 대한 접근이 지나치게 빈번하면 서버 과부하 문제가 쉽게 발생할 수 있다. 안정 해서는 데이터를 좀 더 균등하게 분배하므로 이런 문제가 생길 가능성을 줄인다.
