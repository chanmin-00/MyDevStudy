# 문제 이해 및 설계 범위 확정

자동완성 시스템의 첫 번째 요구사항은 **빠른 응답 속도**이다. 사용자가 검색어를 입력하면 시스템은 100ms 이내에 결과를 반환해야 하며, 그렇지 않으면 사용자 경험이 크게 저하될 수 있다. 

두 번째로 중요한 것은 **연관성**이다. 자동완성으로 제시되는 검색어는 반드시 사용자가 입력한 문자열과 관련이 있어야 한다. 또한 결과는 단순히 나열되는 것이 아니라 **인기도 기반의 랭킹 모델**에 의해 정렬되어야 한다. 마지막으로 이 시스템은 하루 1천만 명이 사용하는 환경에서도 안정적으로 작동해야 하므로, **확장성**과 **고가용성**을 동시에 보장해야 한다.

규모를 추정해 보면 다음과 같다.

- 하루 평균 사용자 수는 1천만 명이다.
- 한 사용자는 하루 10회의 검색을 수행한다고 가정한다.
- 평균 검색어는 네 단어로 이루어지며, 각 단어는 다섯 글자이므로 20바이트 길이가 된다.
- **입력 과정에서 한 글자 입력마다 백엔드로 요청이 전송**되므로, 한 번의 검색은 약 20번의 요청을 발생시킨다.

이 계산을 바탕으로 하면, 시스템은 초당 약 24,000건의 질의(QPS)를 처리해야 하고, 트래픽이 몰릴 경우 **48,000 QPS**까지 대응할 수 있어야 한다. 또한 전체 질의의 20%는 새로운 검색어로, 하루 약 0.4GB의 신규 데이터가 축적된다고 볼 수 있다.

# 개략적 설계안 제시 및 동의 구하기

개략적으로 보면 자동완성 시스템은 크게 두 부분으로 나뉜다. 첫째는 데이터 수집 서비스이고, 둘째는 질의 서비스(query service)이다.

- **데이터 수집 서비스는 사용자가 입력한 검색 질의를 실시간으로 수집하는 역할**을 한다. 일반적으로 데이터가 많은 애플리케이션에서 실시간 수집은 부담이 크기 때문에 이상적이지 않다. 하지만 설계 초안 단계에서는 출발점으로서 의미가 있으며, 이후 상세 설계에서 더 현실적인 구조로 교체될 수 있다.
- 질의 서비스는 사용자가 특정 접두어를 입력했을 때, **빈도 기반으로 가장 인기 있는 다섯 개 검색어를 정렬하여 반환하는 기능**을 담당한다.

질의문과 사용 빈도를 저장하는 **frequency 테이블**이 있다고 가정한다. 초기에는 이 테이블이 비어 있지만, 사용자가 "Twitch", "Twitter", "iwitter", "willo" 등을 순서대로 검색하면 각 검색어가 등장할 때마다 frequency 테이블에 기록되고 빈도 값이 업데이트된다.

<img width="174" height="239" alt="image" src="https://github.com/user-attachments/assets/8e2cb05e-47cc-49db-9ee2-343eeb2d1f10" />

질의 서비스는 이 frequency 테이블을 활용한다. 테이블에는 두 개의 필드가 있다.

- query: 질의 문자열을 저장한다.
- frequency: 해당 질의가 사용된 빈도를 저장한다.

위 상태에서 사용자가 "w"라는 접두어를 입력하면, 시스템은 이 테이블에서 "w"로 시작하는 검색어 중 빈도가 높은 다섯 개를 선택해야 한다. 즉, 자동완성의 **top 5**가 결과로 표시되는 것이다.

이를 SQL로 단순히 구현하면 다음과 같다.

```sql
SELECT *
FROM frequency_table
WHERE query LIKE 'prefix%'
ORDER BY frequency DESC
LIMIT 5;
```

데이터의 양이 적을 때는 이 방식으로도 충분하다. 하지만 데이터가 방대해지고 요청 빈도가 높아지면, 데이터베이스는 곧 **병목 구간**이 된다. 따라서 상세 설계 단계에서는 이를 해결할 수 있는 대안이 필요하다.

# 상세 설계

## 트라이 자료 구조

초기 설계에서는 관계형 데이터베이스를 저장소로 사용하여 인기 검색어 상위 다섯 개를 조회했다. 하지만 이 방식은 데이터가 커질수록 효율적이지 않다. 이를 해결하기 위한 핵심 대안은 **트라이(Trie, 접두어 트리)를 사용하는 것**이다. 

**트라이는 문자열 검색에 특화된 자료 구조로, 자동완성 시스템의 중심에 적합하다.** 트라이는 본래 “retrieval”에서 파생된 이름으로, 문자열을 꺼내는 연산에 최적화되어 있다. 기본 아이디어는 다음과 같다.

- 트라이는 트리 형태의 자료 구조이다.
- 루트 노드는 빈 문자열을 의미한다.
- 각 노드는 문자 하나를 저장하며, 다음에 올 수 있는 문자의 수(예: 알파벳 26개)만큼 자식을 가질 수 있다.
- 하나의 노드는 단어 전체 혹은 접두어 문자열(prefix string)을 나타낸다.

검색어 자동완성 기능을 위해서는 단순 트라이에 빈도 정보까지 저장해야 한다. 즉, 각 노드가 단어와 빈도(frequency)를 함께 보유하면, 인기순 정렬이 가능해진다.

이때 검색어 상위 k개를 찾는 기본 알고리즘은 다음과 같다.

1. 주어진 접두어(prefix)에 해당하는 노드를 찾는다. 시간 복잡도는 **O(p)** (p는 접두어 길이)이다.
2. 해당 노드의 하위 트리를 탐색하여 모든 유효 노드를 찾는다. 시간 복잡도는 **O(c)** (c는 자식 수)이다.
3. 찾은 유효 노드들을 정렬해 상위 k개 검색어를 고른다. 시간 복잡도는 O(c log c)이다.

예를 들어, k=2이고 사용자가 "be"를 입력했다고 하자.

- "be" 노드를 찾는다.
- 하위 트리에서 "beer"(10), "best"(35), "bet"(29)를 찾는다.
- 정렬 후 상위 2개는 "best"(35), "bet"(29)이다.

이 알고리즘은 직관적이지만, 최악의 경우 전체 트라이를 탐색해야 하므로 비효율적이다. 이를 해결하기 위해 두 가지 최적화 기법을 적용할 수 있다.

1. **접두어 최대 길이 제한**
    
    사용자가 아주 긴 검색어를 입력하는 일은 드물다. 따라서 접두어 길이 p를 일정 수준(예: 50)으로 제한하면, 접두어 노드 탐색 복잡도는 O(p)*에서 O(1)로 줄어든다.
    
2. **각 노드에 인기 검색어 캐시**
    
    각 노드에 상위 k개의 인기 검색어를 캐싱해두면, 전체 트리를 탐색할 필요가 없다. 보통 자동완성 제안은 5~10개면 충분하므로 k는 작은 값이다. 예를 들어 "be" 노드에 다음 다섯 개를 저장할 수 있다.
    
    - "best"(35)
    - "bet"(29)
    - "bee"(20)
    - "be"(15)
    - "beer"(10)

이렇게 하면 사용자가 "be"를 입력했을 때, 이미 캐싱된 상위 5개를 즉시 반환할 수 있다. 최적화를 적용한 뒤 시간 복잡도는 크게 개선된다.

- 접두어 노드를 찾는 과정은 O(1)이 된다.
- 인기 검색어 k개를 찾는 과정도 O(1)이 된다.

<img width="576" height="306" alt="image" src="https://github.com/user-attachments/assets/82fe3960-7e07-4323-afa8-5f861df5aa31" />

즉, 전체 알고리즘이 O(1)로 수렴하게 된다. 이는 빠른 응답 속도가 중요한 자동완성 시스템에서 매우 큰 장점이다. 물론 각 노드에 캐시를 저장하는 만큼 메모리 사용량은 늘어나지만, 응답 시간을 획기적으로 줄일 수 있다.

## 데이터 수집 서비스

지금까지 살펴본 설계안은 사용자가 검색창에 타이핑할 때마다 실시간으로 데이터를 수정하는 구조였다. 그러나 이 방식은 두 가지 이유로 실용적이지 않다.

- 첫째, 매일 수천만 건의 질의가 입력되는데 **그때마다 트라이를 갱신하면 질의 서비스가 심각하게 느려진다.**
- 둘째, 일단 트라이가 만들어지고 나면 **인기 검색어는 자주 바뀌지 않으므로, 매 요청마다 갱신할 필요가 없다.**

따라서 현실적인 확장성을 갖추려면 **데이터 수집 서비스와 그 처리 과정**을 새롭게 설계해야 한다. 서비스의 성격에 따라 데이터가 얼마나 자주 취합되고 반영되어야 하는지가 달라진다. 트위터처럼 실시간성이 중요한 애플리케이션은 빠른 주기로 데이터를 취합해야 하지만, 구글 검색처럼 상대적으로 안정된 환경에서는 굳이 자주 갱신할 필요가 없다.

<img width="553" height="222" alt="image" src="https://github.com/user-attachments/assets/ba6cfed3-c4d9-41d9-ae41-a43171c019b6" />

- **데이터 분석 서비스 로그**
    
    데이터 분석 서비스 로그에는 검색창에 입력된 질의의 원본 데이터가 보관된다. 이 로그는 **추가만 이루어지고 수정은 없으며**, 인덱스를 걸지 않는다.
    
- **로그 취합 서버**
    
    로그 취합 서버는 데이터 분석 서비스에서 흘러 들어온 대규모 로그를 집계(aggregation)하여 시스템이 활용할 수 있도록 가공한다.
    
    - 실시간성이 중요한 경우에는 짧은 주기로 취합한다.
    - 대부분의 경우는 일주일 단위로 취합해도 충분하다.
- **취합된 데이터**
    
    취합된 데이터는 주 단위로 집계된 검색어 빈도를 저장한다.
    
- **작업 서버**
    
    작업 서버는 주기적으로 비동기 작업(job)을 실행하는 서버 집합이다. 이 서버는 취합된 데이터를 기반으로 **트라이 자료구조를 새로 구축**하고, 그 결과를 **트라이 데이터베이스**에 저장한다.
    
- **트라이 캐시**
    
    트라이 캐시는 분산 캐시 시스템이다. 트라이 데이터를 메모리에 유지해 질의 서비스의 읽기 성능을 높인다. 보통은 일주일에 한 번 트라이 데이터베이스의 스냅샷을 떠서 캐시를 갱신한다.
    
- **트라이 데이터베이스**
    
    트라이 데이터베이스는 지속적 저장소 역할을 한다. 이를 구현하는 방식은 두 가지로 나눌 수 있다.
    
    1. **문서 저장소(Document Store)**: 주기적으로 트라이를 직렬화해 MongoDB 같은 문서 저장소에 저장한다.
    2. **키-값 저장소(Key-Value Store)**: 트라이의 각 접두어를 해시 테이블의 키로 변환하고, 노드의 데이터를 값으로 변환해 저장한다. 각 트라이 노드가 <key, value> 쌍으로 매핑되는 형태이다.

## 질의 서비스

초기 개략적 설계안에서의 질의 서비스는 데이터베이스를 직접 활용해 상위 다섯 개 인기 검색어를 골라내는 방식이었다. 그러나 데이터가 많아지고 요청이 빈번해지면 이는 비효율적이다. 이를 개선한 새로운 설계안은 다음과 같은 흐름으로 동작한다.

1. 사용자의 검색 질의가 먼저 로드 밸런서로 전달된다.
2. 로드 밸런서는 요청을 API 서버로 라우팅한다.
3. API 서버는 **트라이 캐시**에서 데이터를 조회해 자동완성 제안을 구성한다.
4. 만약 캐시에 데이터가 없다면, API 서버는 데이터베이스에서 값을 가져와 캐시에 채운다. 이후 같은 접두어에 대한 요청이 들어오면 캐시 데이터를 사용해 빠르게 처리할 수 있다.

이 구조를 사용하면 대부분의 요청이 캐시에서 처리되므로 질의 서비스는 훨씬 빨라진다. 다만 캐시 미스(cache miss)가 발생할 수 있는데, 이는 **캐시 서버 메모리가 부족하거나 캐시 서버 자체에 장애가 있을 때 발생한다.**

### 최적화 기법

질의 서비스는 번개처럼 빠르게 응답해야 하므로 다양한 최적화 기법을 적용할 수 있다.

- **AJAX 요청**: 웹 애플리케이션에서는 보통 브라우저가 AJAX 요청을 사용해 자동완성 검색어 목록을 가져온다. 이 방식의 장점은 요청과 응답을 주고받을 때 페이지 전체를 새로 고칠 필요가 없다는 점이다.
- **브라우저 캐싱**: 자동완성 결과는 짧은 시간 안에 크게 변하지 않는다. 따라서 브라우저 캐시에 제안된 검색어를 저장해 두면, 후속 요청에서는 캐시에서 바로 결과를 가져올 수 있다.
    
    구글 검색 엔진이 대표적으로 이런 방식을 사용한다. 예를 들어, 응답 헤더에 cache-control: private, max-age=3600이 포함되어 있다면, 이는 해당 응답이 사용자 개인의 캐시에만 저장될 수 있고 공용 캐시에 저장되어서는 안 되며, 유효 기간은 3600초(1시간)이라는 뜻이다.
    
- **데이터 샘플링**: 대규모 시스템에서 모든 질의 결과를 전부 로깅하면 CPU와 저장 공간이 과도하게 소모된다. 이때는 데이터 샘플링 기법이 유용하다. 즉, N개의 요청 중 1개만 로깅하도록 하여 리소스 사용량을 줄이는 것이다.

## 트라이 연산

트라이는 자동완성 검색 시스템의 핵심 컴포넌트이다. 따라서 트라이와 관련된 주요 연산이 어떻게 동작하는지 이해하는 것이 중요하다. 트라이 연산에는 생성, 갱신, 삭제가 있다.

### 트라이 생성

트라이 생성을 담당하는 것은 작업 서버(Worker)이다. 작업 서버는 데이터 분석 서비스의 로그나 데이터베이스에서 취합된 데이터를 활용하여 새로운 트라이를 만든다. 이렇게 만들어진 트라이는 이후 캐시와 데이터베이스에 반영된다.

### 트라이 갱신

트라이를 갱신하는 방법은 두 가지이다.

1. **주기적 전체 교체 방식**: 매주 한 번씩 새로운 트라이를 생성하고 기존 트라이와 교체한다.
2. **개별 노드 갱신 방식**: 트라이의 각 노드를 직접 갱신한다.

설계안에서는 첫 번째 방식을 채택한다. 이유는 두 번째 방식은 성능이 좋지 않기 때문이다. 트라이가 작을 때는 고려할 수 있지만, 대규모 환경에서는 비효율적이다.

특히 노드 단위 갱신의 경우, 특정 노드를 갱신하면 그 상위 노드(ancestor)들 역시 함께 갱신해야 한다. 이는 각 상위 노드에도 인기 검색어 결과가 캐시되어 있기 때문이다.

### **검색어 삭제**

자동완성 시스템에서는 단순히 인기 검색어만 노출할 수는 없다. **부적절한 검색어는 반드시 걸러야 한다.**

이를 위해 가장 효과적인 방법은 **트라이 캐시 앞에 필터 계층(filter layer)을 두는 것**이다.

- 필터 계층은 규칙에 따라 특정 검색어를 결과에서 제외하거나 변형할 수 있다.
- 데이터베이스에서 부적절한 검색어를 물리적으로 삭제하는 작업은 즉시 할 필요가 없으며, 다음 업데이트 사이클에서 비동기적으로 처리하면 된다.

## 저장소 규모 확장

자동완성 검색어를 제공하는 시스템은 트라이를 기반으로 한다. 그러나 트라이의 크기가 너무 커져서 단일 서버에 담을 수 없는 상황이 발생할 수 있다. 이 경우 **저장소의 규모 확장성**을 확보해야 한다.

가장 먼저 생각할 수 있는 방법은 검색어의 첫 글자를 기준으로 샤딩하는 것이다.

- 서버가 두 대라면, 'a'부터 'm'으로 시작하는 검색어는 첫 번째 서버에, 나머지는 두 번째 서버에 저장한다.
- 서버가 세 대라면, 'a'부터 'i'는 첫 번째 서버, 'j'부터 'r'은 두 번째 서버, 's'부터 'z'는 세 번째 서버에 저장한다.

이 방식은 단순하지만 한계가 있다. 영어 알파벳은 26자뿐이므로 최대 26대로만 나눌 수 있고, 그 이상 확장은 불가능하다. 더 많은 서버로 나누려면 **계층적 샤딩**을 적용해야 한다.

### 계층적 샤딩

계층적 샤딩에서는 첫 번째 글자로 1차 분할을 하고, 두 번째 글자로 다시 나눈다. 예를 들어 'a'로 시작하는 검색어를 네 대 서버에 나누려면,

- 'aa' ~ 'ag'는 첫 번째 서버,
- 'ah' ~ 'an'은 두 번째 서버,
- 'ao' ~ 'al'은 세 번째 서버,
- 나머지는 네 번째 서버에 저장한다.

하지만 이 방식도 완벽하지 않다. 'c'로 시작하는 검색어는 'x'로 시작하는 검색어보다 훨씬 많기 때문에, **균등 분배가 불가능**하다는 문제가 있다.

<img width="506" height="273" alt="image" src="https://github.com/user-attachments/assets/2a6407fb-b0ff-49fc-81b0-6fcd91366390" />

이를 해결하기 위해 제안된 방식은 **과거 질의 데이터 패턴을 분석해 샤딩하는 것**이다. 여기서 샤드 맵 관리자가 중요한 역할을 한다. 샤드 맵 관리자는 특정 검색어가 어느 저장소 서버에 배치되는지 관리한다. 

예를 들어, 's'로 시작하는 검색어의 양이 'l', 'v', 'w', 'x', 'y'로 시작하는 검색어를 모두 합친 것과 비슷하다면, 's' 전용 샤드를 하나 두고, 'l'~'z' 범위를 묶어 또 다른 샤드를 만드는 방식이 가능하다.
