# Kubernetes

쿠버네티스는 **컨테이너화된 애플리케이션을 자동으로 배포, 스케일링, 관리하는 오픈소스 시스템**이다. 

도커가 개별 컨테이너 실행에 집중한다면, 쿠버네티스는 여러 컨테이너가 동시에 운영되는 환경에서 이를 체계적으로 관리하는 데 초점을 맞춘다.

쿠버네티스가 제공하는 대표적인 기능은 다음과 같다.

- 컨테이너 워크로드와 서비스의 관리
- 컨테이너가 죽었을 때 자동으로 재시작
- 트래픽 변화에 따라 컨테이너 수를 늘리거나 줄여주는 오토스케일링
- 다양한 환경에서 동작할 수 있는 높은 이식성과 확장성

이러한 특성 덕분에 쿠버네티스는 단순히 컨테이너 실행 도구가 아니라, **컨테이너 운영의 자동화 관리자**라고 할 수 있다.

## 특징

쿠버네티스는 단순히 컨테이너를 실행하는 수준을 넘어, 서비스 운영에 필요한 다양한 자동화 기능을 제공한다. 대표적으로는 다음과 같은 특징이 있다.

- **서비스 디스커버리와 로드 밸런싱**
    
    컨테이너에 고정된 IP를 지정하지 않아도 서비스 이름으로 접근 가능하며, 여러 인스턴스에 트래픽을 자동으로 분산시켜 준다.
    
- **스토리지 오케스트레이션**
    
    로컬 스토리지, 클라우드 스토리지 등 다양한 저장소를 자동으로 연결해 컨테이너가 데이터를 안정적으로 사용할 수 있도록 한다.
    
- **자동화된 롤아웃과 롤백**
    
    애플리케이션 업데이트 시 점진적으로 배포하여 서비스 중단을 최소화하며, 문제가 생기면 자동으로 이전 버전으로 되돌린다.
    
- **자동화된 빈 패킹(bin packing)**
    
    클러스터 내 리소스를 효율적으로 배치해, 서버 자원을 최적화하여 사용할 수 있게 한다.
    
- **자동화된 복구(self-healing)**
    
    컨테이너가 죽거나 응답하지 않으면 자동으로 다시 실행하거나 교체한다.
    
- **시크릿과 구성 관리**
    
    비밀번호, 인증서와 같은 민감한 정보를 안전하게 저장·관리하고 애플리케이션에 주입할 수 있다.
    

## Kubernetes Cluster 구성

<img width="227" height="256" alt="image" src="https://github.com/user-attachments/assets/d19aef32-5a91-42b4-a2ab-1233f4847d31" />

쿠버네티스에서 애플리케이션을 실행하려면 여러 노드들이 모여 클러스터(Cluster)를 이룬다. 이 클러스터는 크게 **마스터(Master) 노드**와 **워커(Worker) 노드**로 나뉜다.

- **Cluster**
    
    컨테이너화된 애플리케이션을 실행하기 위해 묶여 있는 노드들의 집합이다. 즉, 여러 대의 서버(노드)를 하나의 단일 시스템처럼 다루게 해준다.
    
- **Master**
    
    클러스터 전체를 제어하고, 내부에 있는 모든 노드를 관리하는 가상 머신이다. 쉽게 말해 조정자역할을 하며, 어떤 워커 노드가 어떤 작업을 맡을지 결정하고 배포, 스케줄링을 담당한다. 마스터 노드는 하나 이상 둘 수 있어, 안정성을 위해 다중 마스터 구성이 가능하다.
    
- **Worker**
    
    실제로 컨테이너가 실행되는 노드이다. 마스터가 내린 명령을 받아 컨테이너를 생성하고 애플리케이션을 구동하는 일을 맡는다. 워커 노드는 개수에 제한이 없으며, 서비스가 확장될수록 더 많이 추가할 수 있다.
    

<img width="638" height="336" alt="image" src="https://github.com/user-attachments/assets/2df51daa-a171-43b0-9903-31292a1264ea" />

쿠버네티스 클러스터는 **Master Node**와 **Worker Node**로 나뉘며, 마스터 노드 안에는 클러스터 전체를 관리하기 위한 핵심 컴포넌트들이 들어 있다.

- **kube-api-server**
    
    쿠버네티스의 모든 통신은 kube-api-server를 통해 이루어진다. 클러스터 내에서 중앙 관리 역할을 수행한다.
    
- **kube-controller-manager**
    
    파드들을 관리하는 각종 컨트롤러를 제어한다. 예를 들어 컨테이너 단위가 파괴되거나 장애가 발생하면, 컨테이너를 복원시키고 파드 개수를 일정하게 유지한다.
    
- **kube-scheduler**
    
    리소스를 배분할 수 있는 노드를 선택해 새로운 파드를 배치한다. 즉, 어떤 워커 노드에 컨테이너를 할당할지 결정하는 역할을 한다.
    
- **etcd**
    
    클러스터 내부의 모든 세부 데이터를 저장하는 키-값 저장소이다.
    
- **cloud-controller-manager**
    
    클라우드 서비스와 연결된 컨트롤러들을 관리한다. 예를 들어 AWS, GCP, Azure 같은 클라우드 환경에서 노드나 로드밸런서를 제어할 때 사용된다.
    
- **kubelet**
    
    모든 노드에서 실행되는 에이전트이다. 컨테이너 실행과 상태를 관리하며, 지속적인 헬스체크를 통해 마스터의 kube-api-server와 통신한다.
    
- **kube-proxy**
    
    클러스터 내부의 가상 네트워크를 설정하고 관리한다. 이를 통해 서비스 간 통신과 로드 밸런싱이 가능해진다.
    

## Namespace

<img width="634" height="211" alt="image" src="https://github.com/user-attachments/assets/70ced789-aeb7-4929-891c-44a6e8ee95eb" />

네임스페이스는 **클러스터를 논리적으로 분리하여 사용하는 것**을 의미한다. 물리적인 마스터/워커 노드 위에, 논리적으로 구분된 공간(리소스 단위)을 만들어 관리한다.

- 각 사용자는 **자신에게 권한이 부여된 네임스페이스**에만 접근할 수 있다.
- 예를 들어 dev1 네임스페이스에 대한 권한을 받은 사용자는 **dev1 공간**만 접근 가능하다.
- 따라서 동일한 클러스터를 여러 팀이나 프로젝트에서 함께 쓰더라도, 네임스페이스로 나눠 독립적으로 활용할 수 있다.

## Resource

<img width="313" height="325" alt="image" src="https://github.com/user-attachments/assets/43c9f94c-0766-44ed-a3df-f61412697931" />

- **Namespace**
    
    하나의 물리적 클러스터를 여러 개의 논리적 단위로 나누는 리소스이다. 동일한 클러스터 안에서도 격리된 환경을 제공한다.
    
- **Deployment**
    
    레플리카셋을 관리하면서, 실행해야 할 파드의 **배포 및 관리**를 담당하는 리소스이다. 파드 집합을 선언적으로 관리할 수 있다.
    
- **ReplicaSet**
    
    파드의 개수를 일정하게 유지, 관리하는 리소스이다. 예를 들어 하나의 파드가 죽으면 자동으로 다른 파드를 생성해 대체한다.
    
- **Pod**
    
    실제로 컨테이너가 실행되는 최소 단위이다. 파드 안에 컨테이너가 배포되며, 서비스, 볼륨 등과 연결된다.
    
- **Service**
    
    클러스터 외부에서 내부 파드에 접근할 수 있도록 **고정된 IP**를 제공하는 리소스이다. 쉽게 말해, 파드가 계속 새로 만들어지고 없어져도 외부에서는 같은 주소를 통해 접근할 수 있게 해주는 역할을 한다.
    
- **Volume**
    
    파드의 일부로서, 동일한 파드 내 컨테이너끼리 **데이터를 공유**할 수 있도록 한다. 또한 컨테이너의 데이터를 보관해 유지시킨다. 컨테이너는 보통 일시적으로 실행되기 때문에, 데이터가 날아가지 않도록 볼륨을 사용해 저장한다.
    

<img width="565" height="353" alt="image" src="https://github.com/user-attachments/assets/32e9467f-dc75-4085-9983-47e9d676d87f" />

- **Ingress**
    
    도메인을 붙일 때 사용하는 리소스이다. www.example.com 같은 도메인을 클러스터 서비스와 연결할 때 필요하다.
    
- **Service**
    
    외부에서 컨테이너(Pod)에 접근할 수 있도록 엔드포인트(IP)를 제공한다. 파드가 동적으로 생성, 삭제되어도 고정된 접근 경로를 제공한다.
    
- **ConfigMap / Secret**
    
    Pod에 필요한 환경 변수를 저장하는 리소스이다.
    
    - ConfigMap : 일반 환경변수 저장
    - Secret : 비밀번호, 인증키 등 민감한 값 저장
- **PVC (PersistentVolumeClaim) / PV (PersistentVolume)**
    
    Pod가 외부 저장소를 사용할 수 있도록 연결하는 리소스이다. 데이터를 파드 생명주기와 분리해 보관할 수 있다.
    
- **Deployment / StatefulSet / Job / CronJob / DaemonSet**
    
    Pod의 실행 방식을 제어하는 리소스이다.
    
    - Deployment : 파드를 선언적으로 관리하고 배포
    - StatefulSet : 상태를 가진 파드 관리 (DB 등)
    - Job : 한번 실행 후 종료되는 작업 관리
    - CronJob : 주기적으로 실행되는 작업 관리
    - DaemonSet : 모든 서버에서 항상 실행되어야 하는 파드 관리

## Pod

Pod은 쿠버네티스에서 **컨테이너가 실행되는 실제 장소**이자, 컨테이너를 관리하는 최소 단위이다. 컨테이너를 직접 다루지 않고 Pod 단위로 관리하기 때문에, 운영과 확장이 훨씬 수월하다.

- **컨테이너가 직접 실행되는 장소,** 컨테이너는 Pod 안에서만 실행될 수 있다.
- **컨테이너를 둘러싸는 최소한의 단위,** Pod은 컨테이너를 감싸고, 필요한 네트워크, 스토리지 같은 환경을 함께 제공한다.
- **하나 이상의 컨테이너 그룹,** 하나의 Pod 안에는 컨테이너가 1개일 수도 있고, 여러 개가 함께 실행될 수도 있다.
- **컨테이너를 직접 관리하지 않고 Pod 단위로 관리,** 사용자는 컨테이너를 개별적으로 다루지 않고, Pod을 통해 묶어서 관리한다.

## Service

쿠버네티스에서 Service는 **Pod과 외부 세계를 연결해주는 창구** 역할을 한다. 파드는 동적으로 생성되고 사라지기 때문에 직접 접근하기 어렵지만, Service를 두면 안정적으로 접근할 수 있다.

- **클러스터 외부에서 내부 파드에 접근 가능**
    
    외부 사용자가 Service를 통해 내부 Pod에 접속할 수 있다.
    
- **고정된 IP 주소 할당**
    
    Pod가 교체되더라도 Service는 변하지 않는 IP와 DNS 이름을 제공한다.
    
- **파드 간의 로드 밸런싱 지원**
    
    여러 개의 Pod에 트래픽이 들어오면 Service가 균등하게 분산시킨다.
    
- **하나 또는 여러 개의 포트 지원**
    
    애플리케이션 특성에 따라 단일 포트뿐 아니라 다중 포트도 열어줄 수 있다.
    

## Ingress

Ingress는 **클러스터 외부에서 내부 서비스로 들어오는 트래픽을 관리하는 관문** 역할을 한다. 단순히 IP만 제공하는 Service보다 한 단계 높은 수준(L7)의 제어를 수행한다.

- **네트워크 트래픽 로드밸런싱**
    
    클러스터 외부에서 들어오는 트래픽을 내부 여러 파드로 나누어 전달한다.
    
- **L7 로드밸런싱 수행**
    
    단순 IP 기반이 아닌, **애플리케이션 계층(HTTP/HTTPS)** 수준에서 트래픽을 제어할 수 있다.
    
- **외부 URL 제공**
    
    사용자가 접근할 수 있도록 Service에 외부 URL을 붙여준다.
    
- **트래픽 분산**
    
    하나의 클러스터 안에서도 URL에 따라 서로 다른 서비스로 트래픽을 나눠줄 수 있다.
    
- **보안 인증 지원**
    
    TLS/SSL 인증서를 적용해 보안 통신을 처리할 수 있다.
    
- **도메인 기반 Virtual Hosting**
    
    여러 도메인을 하나의 클러스터에 매핑할 수 있다. (예: app.company.com, api.company.com)
    

## ReplicaSet

ReplicaSet은 쿠버네티스에서 **Pod의 개수를 일정하게 유지, 관리하는 역할**을 한다. 사용자가 원하는 수의 파드가 항상 실행되도록 보장해주기 때문에, 가용성과 안정성을 책임진다.

- **파드의 개수 유지 및 관리**
    
    사용자가 3개의 파드를 원한다면, 항상 3개가 유지되도록 관리한다.
    
- **실행되는 파드를 안정적으로 유지**
    
    파드가 중간에 죽거나 삭제되더라도 새로운 파드를 자동으로 생성해 대체한다.
    
- **파드 개수에 대한 가용성 보장**
    
    즉, 서비스가 끊기지 않도록 파드 개수를 보장하는 원리다. 죽은 파드는 원상 복구된다.
    

## Deployment

Deployment는 **상태가 없는(stateless) 애플리케이션을 배포할 때 사용되는 가장 기본적인 컨트롤러**이다. 즉, 파드와 레플리카셋을 관리하면서 애플리케이션을 안정적으로 운영할 수 있게 한다.

- **레플리카셋 관리**
    
    파드 개수를 유지하는 ReplicaSet을 직접 관리하여, 사용자가 원하는 개수의 파드가 항상 실행되도록 한다.
    
- **앱 배포를 세밀하게 관리**
    
    단순히 파드를 띄우는 것뿐 아니라, 앱 전체 배포 과정을 관리한다.
    
- **파드 개수 유지**
    
    ReplicaSet을 기반으로 파드 개수를 안정적으로 맞추어 서비스 가용성을 보장한다.
    
- **배포 시 롤링 업데이트**
    
    파드를 모두 중단하지 않고 순차적으로 새 버전으로 교체할 수 있다. 또한 필요하면 이전 버전으로 쉽게 롤백할 수 있다.
    

## StatefulSet

StatefulSet은 **상태를 가진(stateful) 애플리케이션을 관리하기 위한 컨트롤러**이다. Deployment와 비슷하지만, 파드의 순서, 저장소, 식별자 관리 측면에서 더 세밀한 제어를 제공한다.

- **파드의 독자성 유지**
    
    동일한 스펙의 컨테이너를 실행하더라도, 각 파드는 고유한 식별자(ID)를 가진다. 그래서 데이터베이스처럼 각 파드가 독립적으로 동작해야 하는 경우에 유리하다.
    
- **순서와 고유성 보장**
    
    파드를 생성, 삭제할 때 순서를 보장하며, 각 파드는 자신만의 고유한 스토리지를 유지한다. 스토리지가 파드마다 다르다는 것이 Deployment와 큰 차이점이다.
    
- **재스케줄링 시 지속성 유지**
    
    파드가 다른 노드로 옮겨 가더라도, 같은 식별자와 저장소를 이어받아 동작할 수 있다.
    
- **고유한 PVC(PersistentVolumeClaim) 설정 가능**
    
    각 파드가 자신만의 스토리지를 가지도록 설정할 수 있다. 따라서 스케일을 확장해도 새로운 파드가 고유한 PV를 확보해 안정적으로 동작한다.
    

## Deployment vs StatefulSet

**Deployment**는 상태가 없는(Stateless) 애플리케이션을 배포할 때 사용되고, **StatefulSet**은 상태를 가진(Stateful) 애플리케이션을 다룰 때 사용된다.

- **Pod 배포 방식**
    - Deployment: Stateless 방식으로, 파드가 모두 동일하며 순서나 고유성이 필요 없다.
    - StatefulSet: Stateful 방식으로, 각 파드가 고유한 ID와 스토리지를 가진다.
- **외부 노출**
    - Deployment: 일반 Service를 통해 외부로 노출된다.
    - StatefulSet: Headless Service를 사용해 파드별로 개별 접근이 가능하다.
- **Pod 선택 방식**
    - Deployment: 요청이 들어오면 무작위로 파드가 선택된다.
    - StatefulSet: 특정 파드를 지정해 접근할 수 있다. (다만 일반적인 Service 요청은 불가능하다.)
- **Rollback 여부**
    - Deployment: ReplicaSet을 가지고 있어 롤백(이전 버전으로 되돌리기)이 가능하다.
    - StatefulSet: ReplicaSet이 없으므로 롤백 기능이 없다.
- **스토리지(PVC/PV)**
    - Deployment: 모든 파드가 하나의 PVC를 공유한다.
    - StatefulSet: 각 파드마다 고유한 PVC가 생성되고, 따라서 고유한 PV를 가진다.

Deployment는 무상태 서비스(예: 웹 서버)를 단순히 확장/축소하기 적합하고, StatefulSet은 상태가 필요한 서비스(예: DB, Kafka)를 안정적으로 관리하는 데 필수적이다.

## Job

Job은 쿠버네티스에서 한 번 실행되고 반드시 성공적으로 끝나야 하는 작업을 보장하는 리소스이다. 파드가 단순히 실행되는 것에 그치지 않고, 지정된 파드가 끝까지 성공 상태로 도달하도록 관리한다는 점이 특징이다. 그래서 데이터 처리, 로그 수집, 마이그레이션처럼 일회성으로 수행되는 작업에 주로 사용된다.

실행 과정에서 파드가 실패하더라도 Job은 자동으로 새로운 파드를 실행해 결국 성공 상태로 완료되도록 한다. 이러한 특성 덕분에 사용자는 작업이 안정적으로 마무리된다는 확신을 가질 수 있다.

또한 Job은 실행 방식을 다양하게 지원한다.

- **단일잡**: 파드 하나만 실행
- **다중잡**: 동일 작업을 여러 번 실행
- **병렬잡**: 여러 파드를 동시에 실행

즉, Job은 일회성, 배치성 작업을 안정적으로 처리하기 위한 리소스이며, 상황에 따라 단순하게도, 또는 병렬적으로도 실행할 수 있는 유연성을 가진다.

## CronJob

CronJob은 쿠버네티스에서 **Job을 주기적으로 실행하도록 스케줄링하는 리소스**이다. 단순히 한 번 실행하고 끝나는 Job과 달리, 정해진 시간마다 반복적으로 실행되어야 하는 작업을 자동으로 처리한다는 점이 특징이다.

이러한 CronJob은 다음과 같은 상황에서 주로 사용된다.

- 정해진 시간에 실행해야 하는 데이터 백업
- 이메일 송신이나 정기 보고서 전송처럼 반복적인 작업

즉, CronJob은 리눅스의 crontab과 매우 유사한 개념이다. 사용자는 원하는 시간 규칙을 설정하기만 하면, 쿠버네티스가 해당 시간마다 Job을 자동으로 실행해준다.

## DaemonSet

DaemonSet은 쿠버네티스에서 **클러스터 전체 노드에 특정 파드를 항상 실행되도록 보장하는 리소스**이다. 특정 노드나 모든 노드에 반드시 배포되어야 하는 파드를 관리할 때 사용된다.

DaemonSet을 사용하면 전체 노드에서 Pod가 한 개씩 실행되도록 보장한다. 따라서 각 노드에 빠짐없이 동일한 파드가 배포되는 것이 핵심이다.

대표적으로 다음과 같은 상황에서 사용된다:

- 로그 수집기 실행
- 모니터링 에이전트 배포
- 큐브프록시가 대표적으로 데몬 셋을 통해서 배포

즉, 클러스터 내 모든 노드에 필수적으로 실행되어야 하는 파드를 자동으로 배포하고 관리하는 역할을 한다.

## Persistent Volume

Persistent Volume(PV)은 특정 파드와 상관없이 독립적인 생명주기를 가지는 스토리지 리소스이다. 파드가 삭제되거나 재시작되더라도 데이터가 보존되기 때문에 안정적인 저장 공간을 제공한다는 점이 특징이다.

프로비저닝 방식은 두 가지로 나뉜다. 관리자가 직접 스토리지를 만들어두는 **정적 방법**, 그리고 요청이 들어올 때 자동으로 스토리지를 생성하는 **동적 방법**이 있다.

PVC(Persistent Volume Claim)가 요청되면, 해당 요청 조건에 맞는 PV가 할당된다. 이때 PV와 PVC는 **1:1 관계로 바인딩**되어 연결되며, 요청된 파드가 스토리지를 사용할 수 있도록 한다.

## Persistent Volume Claim

Persistent Volume Claim은 사용자가 Persistent Volume(PV)을 요청하는 개념이다. 즉, 파드가 직접 스토리지를 사용하는 것이 아니라, 사용자가 PVC를 통해 PV를 할당받고 이를 파드와 연결하는 방식으로 동작한다.

PVC를 정의할 때는 필요한 스토리지의 용량, 접근 방식(ReadWriteOnce 등), 그리고 원하는 스토리지 클래스(셀렉터)를 지정할 수 있다. 이러한 요청 조건에 맞는 PV가 존재하면 자동으로 매핑된다.

핵심은 PV와 PVC가 **1:1 관계로 바인딩**된다는 점이다. 이를 통해 파드는 PVC를 통해 안정적으로 PV에 접근할 수 있게 된다.

## StorageClass

StorageClass는 쿠버네티스에서 **PV(Persistent Volume)로 확보할 스토리지의 종류를 정의하는 리소스**이다. 즉, 관리자가 스토리지의 성격(예: SSD, HDD, 클라우드 스토리지)을 지정해두고, PVC가 요청되었을 때 어떤 스토리지를 연결할지 결정하는 역할을 한다.

특히 PV를 동적으로 생성하는 경우에 StorageClass가 필요하다. PVC가 요청될 때 자동으로 PV를 생성하려면, 최소 하나 이상의 StorageClass가 미리 정의되어 있어야 한다.

정리하면 StorageClass를 미리 정의해두면, PVC 요청 시 조건에 맞는 PV를 **즉시 생성**할 수 있다.

- PV 종류 정의 (예: SSD, HDD 등)
- 동적 프로비저닝 시 필수 요소
- PVC 요청에 맞춰 자동 PV 생성 가능

## PV, PVC 생명 주기

<img width="397" height="361" alt="image" src="https://github.com/user-attachments/assets/7999c2b2-744d-4ba7-9aa5-a1ab308a471a" />

Persistent Volume(PV)은 생성부터 사용 종료 후 초기화까지 네 가지 단계의 생명주기를 가진다. 각 단계는 PV가 어떻게 생성되고, 파드와 연결되며, 사용되고, 마지막에 정리되는지를 보여준다.

1. **Provisioning**
    
    PV가 생성되는 단계이다. 이때는 관리자가 직접 만들어두는 정적 방법과, 요청 시 자동으로 생성되는 동적 방법 두 가지 방식이 있다.
    
2. **Binding**
    
    PVC가 원하는 접근 방식과 스토리지 용량을 요청하면, 조건에 맞는 PV가 PVC와 연결되는 단계이다.
    
3. **Using**
    
    파드가 유지되는 동안 PVC를 통해 PV가 계속 사용되는 단계이다. 파드가 실행 중일 때 해당 PV는 실제로 연결되어 데이터가 유지된다.
    
4. **Reclaiming**
    
    사용이 끝난 PVC는 삭제되고, 그동안 사용되던 PV는 초기화되는 단계이다. 이 과정을 통해 스토리지가 재활용될 수 있다.
    

## Volume 구조

쿠버네티스에서 Pod가 스토리지를 사용하는 과정은 **PVC(Persistent Volume Claim)** 를 통해 이루어진다. Pod는 직접 스토리지에 연결되지 않고, PVC를 통해 PV(Persistent Volume)와 바인딩된다. 이때 PV는 실제 스토리지와 연결되어 데이터를 저장한다.

Volume 구조는 두 가지 방식으로 나뉜다.

1. **정적 프로비저닝**
    
    관리자가 미리 PV를 생성해두고, PVC 요청이 들어오면 조건에 맞는 PV가 바인딩된다. 즉, 스토리지가 고정적으로 준비되어 있는 방식이다.
    
    <img width="576" height="320" alt="image" src="https://github.com/user-attachments/assets/5093d879-04bc-416c-b779-fa6c4ef791e8" />
    
2. **동적 프로비저닝**
    
    PVC 요청이 들어왔을 때, 미리 정의된 StorageClass를 기반으로 PV가 자동으로 생성된다. 이 방식은 필요할 때마다 스토리지를 유연하게 할당할 수 있다는 장점이 있다.
    
    <img width="567" height="327" alt="image" src="https://github.com/user-attachments/assets/5c2a1b60-5a48-4348-9048-cb4b26e340fe" />
    

정리하면, Pod → PVC → PV → Storage 구조로 이어지며, 동적 프로비저닝에서는 **StorageClass**가 추가적으로 동작해 PV 생성을 자동화한다.

## ConfigMap

ConfigMap은 컨테이너와 분리된 환경설정을 제공하는 리소스이다. 애플리케이션 코드와 설정 값을 분리하여 관리할 수 있기 때문에, 컨테이너 이미지를 변경하지 않고도 환경 설정을 손쉽게 바꿀 수 있다는 장점이 있다.

ConfigMap은 **키-값 형태**로 설정 정보를 저장하는 일종의 저장소 역할을 한다. 단순한 문자열 값부터 큰 설정 파일까지 모두 담을 수 있어 활용 범위가 넓다.

또한 동일한 파드라 하더라도 여러 개의 ConfigMap을 동시에 사용할 수 있어, 다양한 설정을 조합해 유연하게 관리할 수 있다.

## Secret

Secret은 보안이 필요한 민감한 정보를 저장하고 관리하기 위한 리소스이다. 자격증명, 비밀번호, 개인 암호화 키와 같은 데이터를 안전하게 다룰 수 있도록 제공된다. 일반 ConfigMap과 비슷하지만, **보안 유지가 필요한 정보에 특화**되어 있다는 점이 가장 큰 차이점이다.

Secret은 Base64 인코딩을 통해 생성되며, 파드와 연결되어 사용된다. 기본적으로 메모리에 저장되기 때문에 디스크에 직접 기록되는 것을 피할 수 있어 보안성이 더 높다.

또한 몇 가지 제한과 규칙이 존재한다.

- **최대 크기**는 개별 Secret당 1MB까지 허용된다.
- 모든 파드에는 자동으로 연결된 기본 Secret 볼륨이 존재한다.

## **ConfigMap, Secret 사용 방법 소개**

ConfigMap과 Secret은 파드 생성 시 함께 참조하여 컨테이너 환경 변수로 주입할 수 있다. ConfigMap은 일반 환경설정 값을, Secret은 보안이 필요한 민감 정보를 관리한다.

파드의 spec 안에서는 envFrom 속성을 통해 ConfigMap과 Secret을 불러온다.

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: edu-msa-configmap
data:
  edu: msa
```

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: edu-msa-secret
data:
  edu: bXNhaA==   # Base64 인코딩된 값
```

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: edu-msa-pod
spec:
  containers:
  - name: edu-msa-container
    image: paastakr/init
    envFrom:
    - configMapRef:
        name: edu-msa-configmap
    - secretRef:
        name: edu-msa-secret
```

<img width="518" height="313" alt="image" src="https://github.com/user-attachments/assets/2742b167-359c-4324-908d-e625d7082648" />

- ConfigMap 값(edu: msa)은 그대로 컨테이너 환경 변수에 들어간다.
- Secret 값(edu: bXNhaA==)은 Base64 인코딩된 상태로 저장되지만, 파드에 전달될 때 디코딩되어 환경 변수에는 평문(edu: msa)으로 들어간다.

즉, 컨테이너 내부에서는 ConfigMap과 Secret이 모두 환경 변수 형태로 사용 가능하다.

## Kubectl 이해

kubectl은 쿠버네티스 API를 사용하여 **클러스터의 컨트롤 플레인과 통신하기 위한 CLI 도구**이다. 사용자는 kubectl 명령어를 통해 리소스를 생성, 조회, 수정, 삭제할 수 있다.

```bash
$ kubectl [command] [TYPE] [NAME] [flags]
```

- **command**: 하나 이상의 리소스에 대해 수행할 동작
    - 예: create, apply, get, describe, delete
- **TYPE**: 리소스 타입
    - pods, deployments, services 등 (대소문자 구분 X, 단수형/복수형/약어 가능)
- **NAME**: 리소스 이름
    - 특정 리소스를 지정할 때 사용, 생략하면 해당 타입의 모든 리소스 표시, 대소문자를 구분한다.
- **flags**: 선택적 플래그
    - 예: -f FILENAME(파일 지정), -n NAMESPACE(네임스페이스 지정), -o wide(추가 정보 출력)

### **(생성/적용) apply**

파일이나 표준입력(stdin)으로부터 리소스에 구성 변경 사항을 적용한다.

```bash
$ kubectl apply -f FILENAME [flags]
```

```bash
$ kubectl apply -f nginx-deployment.yaml
deployment.apps/nginx created
```

- nginx-deployment.yaml 파일에 정의된 Deployment 리소스를 생성하거나, 이미 존재한다면 변경 사항을 적용한다.

### **(생성) create**

파일이나 표준입력에서 하나 이상의 리소스를 새로 생성한다.

```bash
$ kubectl create -f FILENAME [flags]
```

```bash
$ kubectl create -f nginx-deployment.yaml
deployment.apps/nginx created
```

- nginx-deployment.yaml 파일에 정의된 Deployment를 처음으로 생성한다. (apply와 달리 업데이트는 불가능하다.)

### **(조회) get**

하나 이상의 리소스를 조회한다.

```bash
$ kubectl get [TYPE] [flags]
$ kubectl get [TYPE] [NAME]
$ kubectl get [TYPE] [NAME] [flags]
```

```bash
$ kubectl get pods
```

- 현재 클러스터에 실행 중인 모든 Pod 목록을 확인한다. 상태, 재시작 횟수, 실행 시간 등의 기본 정보가 표시된다.

### **(상세조회) describe**

하나 이상의 리소스의 상세 상태를 조회한다.

```bash
$ kubectl describe -f FILENAME
```

```bash
$ kubectl describe pod nginx-599d75d6b-4zhsz
```

- 특정 Pod(nginx-599d75d6b-4zhsz)의 상세 정보를 출력한다. 이벤트, 컨테이너 상태, 네트워크 정보 등 get보다 더 구체적인 내용을 확인할 수 있다.

### **(로그조회) logs**

특정 이름을 가진 리소스의 로그 정보를 출력한다.

```bash
$ kubectl logs [flags] [NAME]
```

```bash
$ kubectl logs -f edu-msa-zuul-647b787d7-g5st7
```

- edu-msa-zuul-647b787d7-g5st7라는 Pod의 로그를 실시간(-f)으로 확인한다. 애플리케이션 실행 상태나 에러 메시지를 디버깅할 때 유용하다.

### **(Editor 수정) edit**

특정 이름을 가진 리소스의 설정을 직접 수정한다. (기본 편집기가 열림)

```bash
$ kubectl edit [TYPE] [NAME]
```

```bash
$ kubectl edit deployment nginx
```

- nginx라는 Deployment의 설정을 편집기에서 바로 수정한다. 예를 들어 replica 수나 이미지 버전을 변경할 때 사용할 수 있다.

## **Kubernetes 리소스 관리**

쿠버네티스 리소스는 **YAML 또는 JSON 형식의 구성 파일**로 정의할 수 있다. 이 파일 안에는 리소스 종류(kind), API 버전(apiVersion), 메타데이터(metadata), 스펙(spec) 등의 정보가 담기며, 이를 통해 원하는 파드나 서비스 등을 생성하고 관리할 수 있다.

- **YAML 예시**
    
    ```yaml
    apiVersion: v1
    kind: Pod
    metadata:
      labels:
        run: nginx
      name: nginx
    spec:
      containers:
      - image: nginx
        name: nginx
    ```
    
- **JSON 예시**
    
    ```json
    {
      "kind": "Pod",
      "apiVersion": "v1",
      "metadata": {
        "name": "nginx",
        "labels": {
          "run": "nginx"
        }
      },
      "spec": {
        "containers": [
          {
            "name": "nginx",
            "image": "nginx"
          }
        ]
      }
    }
    ```
    
    - 이렇게 정의된 구성 파일은 kubectl 명령어를 사용하여 클러스터에 적용할 수 있다.
- **kubectl 실행 예시**
    
    ```bash
    $ kubectl create -f nginx.yaml
    pod/nginx created
    
    $ kubectl get pod nginx
    NAME    READY   STATUS    RESTARTS   AGE
    nginx   1/1     Running   0          10s
    ```
    
    - 첫 번째 명령어는 nginx.yaml 파일로부터 Pod를 생성하고, 두 번째 명령어는 해당 Pod의 실행 상태를 확인하는 예시이다.

즉, 쿠버네티스 리소스는 **YAML/JSON 파일로 정의 → kubectl 명령어로 생성 및 관리**라는 흐름으로 관리된다.

## yaml 파일 작성 방법

쿠버네티스에서 리소스를 정의할 때는 apiVersion과 kind를 통해 어떤 API 버전과 어떤 리소스 타입을 생성할지를 명시해야 한다.

### 디플로이먼트 예시

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: edu-msa-board
  labels:
    app: board-msa
spec:
  replicas: 1
  selector:
    matchLabels:
      app: board-msa
  template:
    metadata:
      labels:
        app: board-msa
```

- **apiVersion**
    
    특정 리소스를 생성하기 위해 사용할 쿠버네티스 API 버전을 명세한다. 여기서는 apps/v1 버전을 사용한다.
    
- **kind**
    
    어떤 종류의 리소스를 생성할지 명시한다. 여기서는 Deployment를 정의하여 애플리케이션 배포를 관리한다.
    
- **metadata**
    
    리소스에 이름을 부여하고 고유하게 구분할 수 있는 데이터이다.
    
- **metadata.name**
    
    리소스의 이름을 지정한다. 예시에서는 edu-msa-board라는 이름이 부여되었다.
    
- **metadata.labels**
    
    → 키-값 쌍으로 구성되어, 특정 리소스를 그룹화하거나 검색할 때 사용된다.
    
- **metadata.labels.app**
    
    레이블의 실제 값이다. 여기서는 board-msa라는 값을 레이블로 설정해, 다른 리소스와 연계 시 식별 기준으로 활용할 수 있다.
    
- **spec**
    
    생성하고자 하는 리소스의 동작 방식을 정의하는 부분이다.
    
- **spec.replicas**
    
    동시에 몇 개의 파드를 띄울지 개수를 설정한다. 예시에서는 1로 설정되어 있어, 파드 한 개만 실행된다.
    
- **spec.selector**
    
    어떤 파드를 컨트롤하고 감시해야 하는지를 정의한다.
    
- **spec.selector.matchLabels**
    
    metadata.labels와 동일한 키-값 쌍으로 매핑되어, 동일한 레이블을 가진 파드를 찾아 상태를 관리한다. 즉, 레이블이 app: board-msa인 파드들을 카운팅해 상태를 측정한다.
    
- **spec.template**
    
    디플로이먼트가 어떤 파드를 실행할지를 정의하는 부분이다. 파드의 구조와 설정이 여기에 기술된다.
    
- **spec.template.metadata**
    
    파드의 메타데이터를 정의하며, 주로 레이블(labels)을 지정한다. 이 값은 spec.selector.matchLabels와 동일해야 하며, 동일한 레이블을 가진 파드만 디플로이먼트가 관리한다.
    
- **spec.template.spec**
    
    실행할 컨테이너의 세부 설정을 정의한다.
    
- **spec.template.spec.containers[]**
    
    여러 개의 컨테이너를 정의할 수 있으며, 각 컨테이너의 이름, 사용할 이미지, 포트 번호 등을 설정한다.
    
- **name: board-msa**
    
    컨테이너 이름을 지정한다. 여기서는 board-msa라는 이름의 컨테이너가 실행된다.
    
- **image: paastakr/edu-msa-board:latest**
    
    사용할 컨테이너 이미지를 명시한다. latest 태그는 최신 버전을 의미한다.
    
- **imagePullPolicy: Always**
    
    항상 이미지를 새로 받아오도록 설정한다.
    
- **ports.containerPort: 28082**
    
    컨테이너 내부에서 사용할 포트 번호를 지정한다.
    
- **spec.template.spec.imagePullSecrets**
    
    레지스트리에서 이미지를 가져올 때 필요한 인증 정보를 지정한다. 예시에서는 edu-msa-secret이라는 시크릿을 사용해 이미지 저장소에 접근한다.
    
- **spec.template.spec.nodeSelector**
    
    파드를 특정 노드에 배포하도록 지정한다. 예시에서는 kubernetes.io/hostname: paas-ta-worker-1 조건에 맞는 노드에만 파드가 배포된다.
    

### 서비스 예시

```yaml
apiVersion: v1
kind: Service
metadata:
  name: edu-msa-board
  labels:
    app: board-msa
spec:
  ports:
  - nodePort: ${EDU_MSA_BOARD}   # 외부 접근 포트
    port: 28082                  # 서비스 내부 포트
    protocol: TCP                # 통신 프로토콜
    targetPort: 28082            # 컨테이너 포트
  selector:
    app: board-msa
  type: NodePort
```

- **spec.ports[].nodePort**
    
    외부에서 접근 가능한 포트 번호를 지정한다. (NodePort는 보통 30000~32767 범위를 사용)
    
- **spec.ports[].port**
    
    클러스터 내부에서 사용하는 서비스 포트 번호이다.
    
- **spec.ports[].protocol**
    
    사용할 네트워크 프로토콜을 지정한다. (기본값은 TCP)
    
- **spec.ports[].targetPort**
    
    접근하고자 하는 컨테이너 포트 번호를 설정한다.
    
- **spec.type: NodePort**
    
    서비스를 외부에 노출하는 방식이다. NodePort를 사용하면 클러스터의 각 노드가 지정된 포트를 열고, 해당 포트로 들어오는 요청을 서비스에 연결된 파드로 전달한다.
    
    즉, 클러스터 외부에서 <NodeIP>:<NodePort> 형태로 접근 가능하다.
    

## **YAML 파일 통합**

쿠버네티스에서는 보통 **Deployment**와 **Service** 같은 리소스를 각각의 YAML 파일로 작성한다. 하지만 서로 관련된 리소스를 한 번에 배포하기 위해 하나의 YAML 파일에 통합할 수도 있다.

이를 위해 YAML 문서 구분자 ---를 사용한다. 이 구분자를 기준으로 여러 리소스를 이어 붙이면, kubectl apply -f 명령으로 한꺼번에 생성 및 관리할 수 있다.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: edu-msa-board
  labels:
    app: board-msa
spec:
  replicas: 1
  selector:
    matchLabels:
      app: board-msa
  template:
    metadata:
      labels:
        app: board-msa
    spec:
      containers:
      - name: board-msa
        image: paastakr/edu-msa-board:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 28082
---
apiVersion: v1
kind: Service
metadata:
  name: edu-msa-board
  labels:
    app: board-msa
spec:
  ports:
  - nodePort: 30201
    port: 28082
    protocol: TCP
    targetPort: 28082
  selector:
    app: board-msa
  type: NodePort
```

## Kubernetes 배포 도구

쿠버네티스는 다양한 환경에서 동작할 수 있기 때문에, 설치와 배포를 자동화하고 단순화하는 여러 도구들이 존재한다. 대표적으로는 kubeadm, kops, kubespray가 있다.

### **kubeadm**

일반적인 서버 클러스터 환경에서도 쿠버네티스를 쉽게 설치할 수 있도록 도와주는 관리 툴이다. 클러스터를 빠르고 일관되게 초기화하고 설정할 수 있어 실습이나 기본 환경 구축에 많이 사용된다.

### **kops**

자동화된 프로비저닝 시스템으로, 특히 **AWS 환경**에 특화되어 있다. 손쉽게 클러스터를 생성, 업데이트, 삭제할 수 있어 클라우드 환경에서 빠르게 쿠버네티스를 배포할 수 있다.

### **kubespray**


**Ansible 기반 오픈소스 도구**로, 쿠버네티스 클러스터를 유연하게 배포 및 관리할 수 있다. AWS, GCP, Azure, OpenStack, vSphere, Oracle Cloud 등 다양한 플랫폼을 지원한다.

멀티 클라우드나 하이브리드 환경에서 특히 강력하다.
